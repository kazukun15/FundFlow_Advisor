import io
import os
import streamlit as st
import pdfplumber
import pandas as pd
import pytesseract
from pdf2image import convert_from_bytes
import google.generativeai as genai

# â”€â”€â”€ è¨­å®š â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.set_page_config(page_title="FundFlow Advisor", layout="wide")
api_key = st.secrets.get("google", {}).get("api_key")
if not api_key:
    st.error("âŒ `.streamlit/secrets.toml` ã« [google] api_key ã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚")
    st.stop()
genai.configure(api_key=api_key)

# â”€â”€â”€ ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£é–¢æ•° â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def extract_tables_from_pdf(buf: bytes) -> pd.DataFrame:
    with pdfplumber.open(io.BytesIO(buf)) as pdf:
        tables = [t for p in pdf.pages for t in (p.extract_tables() or [])]
    dfs = [pd.DataFrame(t[1:], columns=t[0]) for t in tables if len(t) > 1]
    return pd.concat(dfs, ignore_index=True) if dfs else pd.DataFrame()

def fallback_ocr_pdf(buf: bytes) -> str:
    imgs = convert_from_bytes(buf)
    return "\n".join(pytesseract.image_to_string(img, lang="jpn") for img in imgs)

def normalize_df(df: pd.DataFrame) -> pd.DataFrame:
    df = df.copy()
    df.columns = [str(c).strip() for c in df.columns]
    for c in df.columns:
        try:
            s = df[c].map(lambda x: str(x).replace(",", "").strip())
            df[c] = pd.to_numeric(s, errors="ignore")
        except Exception:
            st.warning(f"âš ï¸ åˆ— '{c}' ã®æ­£è¦åŒ–ã«å¤±æ•—ã€‚å…ƒã®ã¾ã¾ä¿æŒã—ã¾ã™ã€‚")
    return df

def reconcile_reports(pub_df: pd.DataFrame, others: dict) -> pd.DataFrame:
    base = pub_df.select_dtypes(include="number").sum().sum()
    rows = []
    for name, df in others.items():
        s = df.select_dtypes(include="number").sum().sum()
        if base != s:
            rows.append({
                "ãƒ¬ãƒãƒ¼ãƒˆ": name,
                "å…¬é‡‘æ—¥è¨ˆåˆè¨ˆ": base,
                "ä»–æ—¥å ±åˆè¨ˆ": s,
                "å·®ç•°": s - base
            })
    return pd.DataFrame(rows)

def generate_ai_suggestions(df_diff: pd.DataFrame) -> str:
    prompt = (
        "ä»¥ä¸‹ã®æ—¥å ±çªåˆçµæœã«ã¤ã„ã¦ã€å·®ç•°ã®åŸå› ã‚’ç®‡æ¡æ›¸ãã§ç¤ºã—ã¦ãã ã•ã„ã€‚\n\n"
        + df_diff.to_markdown(index=False)
    )
    resp = genai.chat.completions.create(
        model="gemini-2.5",
        prompt=[{"author":"user","content":prompt}],
        temperature=0.7
    )
    return resp.candidates[0].message.content

# â”€â”€â”€ ãƒ¡ã‚¤ãƒ³ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def main():
    st.title("FundFlow Advisor ğŸ¦")
    st.markdown("**PDF**ï¼**Excel**ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã€æ—¥å ±ã®çªåˆã¨åŸå› ç¤ºå”†ã‚’è¡Œã„ã¾ã™ã€‚\n\n"
                "- **ã¾ãš** å·¦ã‚µã‚¤ãƒ‰ãƒãƒ¼ã§ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠ\n"
                "- **æ¬¡ã«** ä¸Šéƒ¨ã®ã‚¿ãƒ–ã§ã€Œãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ã€ã€Œå·®ç•°ã€ã€ŒAIç¤ºå”†ã€ã‚’åˆ‡ã‚Šæ›¿ãˆ")

    uploaded = st.sidebar.file_uploader(
        "ğŸ“ ãƒ•ã‚¡ã‚¤ãƒ«é¸æŠ (PDF / XLS / XLSX)",
        type=None,
        accept_multiple_files=True
    )
    if not uploaded:
        st.sidebar.info("ã“ã“ã§ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")
        return

    # å…¬é‡‘æ—¥è¨ˆã¨ä»–æ—¥å ±ã«æŒ¯ã‚Šåˆ†ã‘
    pub_df = pd.DataFrame()
    other = {}
    allowed = {".pdf", ".xls", ".xlsx"}

    for f in uploaded:
        name, ext = f.name, os.path.splitext(f.name)[1].lower()
        buf = f.read()
        if ext not in allowed:
            st.sidebar.error(f"{name} ã¯éå¯¾å¿œã§ã™ã€‚PDF/XLS/XLSXã‚’ã”åˆ©ç”¨ãã ã•ã„ã€‚")
            continue

        if ext == ".pdf":
            df = extract_tables_from_pdf(buf)
            if df.empty:
                st.sidebar.warning(f"{name} ã®ãƒ†ãƒ¼ãƒ–ãƒ«æŠ½å‡ºå¤±æ•—ã€‚OCRã‚’å®Ÿè¡Œã—ã¾ã™ã€‚")
                st.sidebar.text_area(f"OCR({name})", fallback_ocr_pdf(buf), height=150)
            df = normalize_df(df)
            if pub_df.empty:
                pub_df = df
            else:
                other[name] = df

        else:
            engine = "xlrd" if ext==".xls" else "openpyxl"
            try:
                sheets = pd.read_excel(io.BytesIO(buf), sheet_name=None, engine=engine)
            except Exception as e:
                st.sidebar.error(f"{name} èª­è¾¼ã‚¨ãƒ©ãƒ¼: {e}")
                continue
            for sheet, sdf in sheets.items():
                key = f"{name}:{sheet}"
                sdf = normalize_df(sdf)
                other[key] = sdf

    if pub_df.empty or not other:
        st.warning("å…¬é‡‘æ—¥è¨ˆ(PDF)ã¨ä»–æ—¥å ±(Excel/PDF)ã‚’æœ€ä½1ä»¶ãšã¤å«ã‚ã¦ãã ã•ã„ã€‚")
        return

    # çªåˆã¨AIç¤ºå”†ã‚’å®Ÿè¡Œ
    df_diff = reconcile_reports(pub_df, other)
    ai_text = generate_ai_suggestions(df_diff) if not df_diff.empty else ""

    # ä¸Šéƒ¨ã‚¿ãƒ–ã§åˆ‡ã‚Šæ›¿ãˆ
    tab1, tab2, tab3 = st.tabs(["ğŸ” ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼", "ğŸ“Š å·®ç•°ã‚µãƒãƒªãƒ¼", "ğŸ¤– AIç¤ºå”†"])
    with tab1:
        st.subheader("â–  å…¬é‡‘æ—¥è¨ˆãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼")
        st.markdown(pub_df.head(10).to_markdown())
        for name, df in other.items():
            st.subheader(f"â–  ä»–æ—¥å ±ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ï¼š{name}")
            st.markdown(df.head(10).to_markdown())

    with tab2:
        if df_diff.empty:
            st.success("ğŸ‰ å·®ç•°ã¯æ¤œå‡ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸã€‚")
        else:
            st.subheader("â–  å·®ç•°ã‚µãƒãƒªãƒ¼")
            st.table(df_diff)

    with tab3:
        if df_diff.empty:
            st.info("å·®ç•°ãŒãªã„ãŸã‚AIç¤ºå”†ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚")
        else:
            st.subheader("â–  Gemini 2.5 ã«ã‚ˆã‚‹å·®ç•°åŸå› ç¤ºå”†")
            st.markdown(ai_text)

if __name__ == "__main__":
    main()
