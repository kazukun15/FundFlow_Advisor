import os
import io

import streamlit as st
import pdfplumber
import pandas as pd
import pytesseract
from pdf2image import convert_from_bytes
import openai

# â”€â”€â”€ OpenAI API Key è¨­å®š â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# â‘  secrets.toml ã® [openai] ã‚»ã‚¯ã‚·ãƒ§ãƒ³
# â‘¡ ç’°å¢ƒå¤‰æ•° OPENAI_API_KEY
# â‘¢ èµ·å‹•æ™‚ã®ãƒ†ã‚­ã‚¹ãƒˆå…¥åŠ›ãƒ•ã‚©ãƒ¼ãƒ 
api_key = None
# secrets.toml ã« "openai": {"api_key": "..."} ãŒã‚ã‚‹å ´åˆ
if st.secrets.get("openai", {}).get("api_key"):
    api_key = st.secrets["openai"]["api_key"]
# æ¬¡ã«ç’°å¢ƒå¤‰æ•°
elif os.getenv("OPENAI_API_KEY"):
    api_key = os.getenv("OPENAI_API_KEY")
# æœ€å¾Œã«ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›
else:
    api_key = st.sidebar.text_input(
        "OpenAI API Key",
        type="password",
        help="secrets.toml ã¾ãŸã¯ç’°å¢ƒå¤‰æ•°ã«è¨­å®šãŒãªã‘ã‚Œã°ã“ã¡ã‚‰ã«å…¥åŠ›"
    )

if not api_key:
    st.error("âŒ OpenAI API Key ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
    st.stop()

openai.api_key = api_key

# â”€â”€â”€ PDFæŠ½å‡ºé–¢æ•° â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def extract_tables_from_pdf(file_bytes: bytes) -> pd.DataFrame:
    with pdfplumber.open(io.BytesIO(file_bytes)) as pdf:
        tables = []
        for page in pdf.pages:
            tables.extend(page.extract_tables() or [])
    dfs = []
    for table in tables:
        if table and len(table) > 1:
            df = pd.DataFrame(table[1:], columns=table[0])
            dfs.append(df)
    return pd.concat(dfs, ignore_index=True) if dfs else pd.DataFrame()

def fallback_ocr_pdf(file_bytes: bytes) -> str:
    images = convert_from_bytes(file_bytes)
    text = ""
    for img in images:
        text += pytesseract.image_to_string(img, lang='jpn')
    return text

# â”€â”€â”€ ãƒ‡ãƒ¼ã‚¿æ­£è¦åŒ–é–¢æ•° â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def normalize_df(df: pd.DataFrame) -> pd.DataFrame:
    df = df.copy()
    df.columns = df.columns.str.strip()
    for col in df.columns:
        if df[col].dtype == object:
            df[col] = df[col].str.replace(',', '').str.strip()
        try:
            df[col] = pd.to_numeric(df[col])
        except:
            pass
    return df

# â”€â”€â”€ çªåˆé–¢æ•° â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def reconcile_reports(pub_df: pd.DataFrame, other_dfs: dict) -> list[dict]:
    pub_sum = (
        pub_df['é‡‘é¡'].sum()
        if 'é‡‘é¡' in pub_df.columns
        else pub_df.select_dtypes(include='number').sum().sum()
    )
    results = []
    for name, df in other_dfs.items():
        df_sum = (
            df['é‡‘é¡'].sum()
            if 'é‡‘é¡' in df.columns
            else df.select_dtypes(include='number').sum().sum()
        )
        if pub_sum != df_sum:
            results.append({
                'ãƒ¬ãƒãƒ¼ãƒˆ': name,
                'å…¬é‡‘æ—¥è¨ˆåˆè¨ˆ': pub_sum,
                'ä»–æ—¥å ±åˆè¨ˆ': df_sum,
                'å·®ç•°': df_sum - pub_sum
            })
    return results

# â”€â”€â”€ AIç¤ºå”†ç”Ÿæˆé–¢æ•° â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def generate_ai_suggestions(suggestions: list[dict]) -> str:
    prompt = (
        "ä»¥ä¸‹ã®æ—¥å ±çªåˆçµæœã«ã¤ã„ã¦ã€å·®ç•°ã®åŸå› ã‚’ç®‡æ¡æ›¸ãã§ç¤ºã—ã¦ãã ã•ã„ã€‚\n\n"
        + pd.DataFrame(suggestions).to_markdown(index=False)
    )
    resp = openai.ChatCompletion.create(
        model='gemini-2.5',
        messages=[{"role": "user", "content": prompt}],
        temperature=0.7
    )
    return resp.choices[0].message.content

# â”€â”€â”€ Streamlit UI â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def main():
    st.set_page_config(page_title="FundFlow Advisor", layout="wide")
    st.title("FundFlow Advisor")
    st.markdown("å…¬é‡‘æ—¥è¨ˆPDFã¨å„éƒ¨ç½²æ—¥å ±PDFã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦çªåˆã—ã€Gemini 2.5ã§åŸå› ç¤ºå”†ã¾ã§è¡Œã†ã‚¢ãƒ—ãƒªã§ã™ã€‚")

    pub_file = st.file_uploader("ğŸ“‘ å…¬é‡‘æ—¥è¨ˆPDFã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", type='pdf')
    other_files = st.file_uploader(
        "ğŸ“‘ ä»–éƒ¨ç½²æ—¥å ±PDFã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ï¼ˆè¤‡æ•°å¯ï¼‰",
        type='pdf',
        accept_multiple_files=True
    )

    if not pub_file or not other_files:
        st.info("ã¾ãšã¯ä¸¡æ–¹ã®PDFã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")
        return

    # å…¬é‡‘æ—¥è¨ˆè§£æ
    buf = pub_file.read()
    df_pub = extract_tables_from_pdf(buf)
    if df_pub.empty:
        st.warning("å…¬é‡‘æ—¥è¨ˆã®ãƒ†ãƒ¼ãƒ–ãƒ«æŠ½å‡ºã«å¤±æ•—ã—ã¾ã—ãŸã€‚OCRçµæœã‚’ã”ç¢ºèªãã ã•ã„ã€‚")
        st.text_area("OCRï¼ˆå…¬é‡‘æ—¥è¨ˆï¼‰", fallback_ocr_pdf(buf), height=200)
    df_pub = normalize_df(df_pub)
    st.subheader("å…¬é‡‘æ—¥è¨ˆãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼")
    st.dataframe(df_pub)

    # ä»–éƒ¨ç½²æ—¥å ±è§£æ
    other_dfs = {}
    for f in other_files:
        buf = f.read()
        df = extract_tables_from_pdf(buf)
        if df.empty:
            st.warning(f"{f.name} ã®ãƒ†ãƒ¼ãƒ–ãƒ«æŠ½å‡ºã«å¤±æ•—ã—ã¾ã—ãŸã€‚OCRçµæœã‚’è¡¨ç¤ºã—ã¾ã™ã€‚")
            st.text_area(f"OCRï¼ˆ{f.name}ï¼‰", fallback_ocr_pdf(buf), height=200)
        df = normalize_df(df)
        other_dfs[f.name] = df
        st.subheader(f"{f.name} ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼")
        st.dataframe(df)

    # çªåˆï¼†AIç¤ºå”†
    diffs = reconcile_reports(df_pub, other_dfs)
    if diffs:
        st.subheader("â–¶ å·®ç•°ã‚µãƒãƒª")
        st.table(pd.DataFrame(diffs))
        st.subheader("â–¶ Gemini 2.5 ã«ã‚ˆã‚‹åŸå› ç¤ºå”†")
        suggestion = generate_ai_suggestions(diffs)
        st.markdown(suggestion)
    else:
        st.success("ğŸ‰ å·®ç•°ã¯æ¤œå‡ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸã€‚")

if __name__ == "__main__":
    main()
