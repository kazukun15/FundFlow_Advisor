import io
import os
import streamlit as st
import pdfplumber
import pandas as pd
import pytesseract
from pdf2image import convert_from_bytes
import google.generativeai as genai

# â”€â”€â”€ Google API Key è¨­å®š (Secrets) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
api_key = st.secrets.get("google", {}).get("api_key")
if not api_key:
    st.error("âŒ `.streamlit/secrets.toml` ã« [google] api_key ã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚")
    st.stop()
genai.configure(api_key=api_key)

# â”€â”€â”€ PDFè§£æ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def extract_tables_from_pdf(file_bytes: bytes) -> pd.DataFrame:
    with pdfplumber.open(io.BytesIO(file_bytes)) as pdf:
        tables = [tbl for page in pdf.pages for tbl in (page.extract_tables() or [])]
    dfs = [pd.DataFrame(tbl[1:], columns=tbl[0]) for tbl in tables if len(tbl) > 1]
    return pd.concat(dfs, ignore_index=True) if dfs else pd.DataFrame()

def fallback_ocr_pdf(file_bytes: bytes) -> str:
    images = convert_from_bytes(file_bytes)
    return "".join(pytesseract.image_to_string(img, lang="jpn") for img in images)

# â”€â”€â”€ ãƒ‡ãƒ¼ã‚¿æ­£è¦åŒ– â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def normalize_df(df: pd.DataFrame) -> pd.DataFrame:
    df = df.copy()
    # åˆ—åã‚’æ–‡å­—åˆ—åŒ–ï¼†trim
    df.columns = [str(col).strip() for col in df.columns]
    for col in df.columns:
        try:
            # å…¨è¦ç´ ã‚’æ–‡å­—åˆ—åŒ–â†’ã‚«ãƒ³ãƒé™¤å»ãƒ»trim
            s = df[col].astype(str).map(lambda x: x.replace(",", "").strip())
            # æ•°å€¤åŒ–å¯èƒ½ãªã‚‰å¤‰æ›
            df[col] = pd.to_numeric(s, errors="ignore")
        except Exception as e:
            raise ValueError(f"åˆ— '{col}' ã®æ­£è¦åŒ–ã§ã‚¨ãƒ©ãƒ¼: {e}")
    return df

# â”€â”€â”€ ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ç”¨ã‚µãƒ‹ã‚¿ã‚¤ã‚º â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def sanitize_df_for_display(df: pd.DataFrame) -> pd.DataFrame:
    df = df.copy()
    for col in df.columns:
        if df[col].dtype == object:
            df[col] = df[col].map(lambda x: x if isinstance(x, (str,int,float,bool,type(None))) else str(x))
    return df

# â”€â”€â”€ çªåˆãƒ­ã‚¸ãƒƒã‚¯ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def reconcile_reports(pub_df: pd.DataFrame, other_dfs: dict) -> list[dict]:
    pub_sum = pub_df.select_dtypes(include="number").sum().sum()
    results = []
    for name, df in other_dfs.items():
        df_sum = df.select_dtypes(include="number").sum().sum()
        if pub_sum != df_sum:
            results.append({
                "ãƒ¬ãƒãƒ¼ãƒˆ": name,
                "å…¬é‡‘æ—¥è¨ˆåˆè¨ˆ": pub_sum,
                "ä»–æ—¥å ±åˆè¨ˆ": df_sum,
                "å·®ç•°": df_sum - pub_sum
            })
    return results

# â”€â”€â”€ AIç¤ºå”†ç”Ÿæˆ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def generate_ai_suggestions(suggestions: list[dict]) -> str:
    df = pd.DataFrame(suggestions)
    prompt = (
        "ä»¥ä¸‹ã®æ—¥å ±çªåˆçµæœã«ã¤ã„ã¦ã€å·®ç•°ã®åŸå› ã‚’ç®‡æ¡æ›¸ãã§ç¤ºã—ã¦ãã ã•ã„ã€‚\n\n"
        + df.to_markdown(index=False)
    )
    resp = genai.chat.completions.create(
        model="gemini-2.5",
        prompt=[{"author":"user","content":prompt}],
        temperature=0.7
    )
    return resp.candidates[0].message.content

# â”€â”€â”€ Streamlit UI â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def main():
    st.set_page_config(page_title="FundFlow Advisor", layout="wide")
    st.title("FundFlow Advisor ğŸ“Š")
    st.markdown("PDF/Excelã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã€æ—¥å ±ã®çªåˆã¨Gemini 2.5ã«ã‚ˆã‚‹åŸå› ç¤ºå”†ã‚’è¡Œã„ã¾ã™ã€‚")

    uploaded_files = st.file_uploader(
        "ğŸ“ ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ï¼ˆPDF / XLS / XLSXï¼‰",
        type=None,
        accept_multiple_files=True
    )
    if not uploaded_files:
        st.info("ã¾ãšã¯ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")
        return

    allowed_exts = {".pdf", ".xls", ".xlsx"}
    pub_df = pd.DataFrame()
    other_dfs = {}

    for f in uploaded_files:
        name = f.name
        ext = os.path.splitext(name)[1].lower()
        buf = f.read()

        if ext not in allowed_exts:
            st.error(f"ğŸš« {name} ã¯ã‚µãƒãƒ¼ãƒˆå¤–ã®ãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼ã§ã™ã€‚")
            continue

        # PDF
        if ext == ".pdf":
            df = extract_tables_from_pdf(buf)
            if df.empty:
                st.warning(f"[PDF] {name} ã®ãƒ†ãƒ¼ãƒ–ãƒ«æŠ½å‡ºå¤±æ•—ã€‚OCRè¡¨ç¤ºã—ã¾ã™ã€‚")
                st.text_area(f"OCR({name})", fallback_ocr_pdf(buf), height=200)
                df = pd.DataFrame()
            df = normalize_df(df)
            if pub_df.empty:
                pub_df = df
                st.subheader(f"å…¬é‡‘æ—¥è¨ˆãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ ({name})")
                st.dataframe(sanitize_df_for_display(pub_df))
            else:
                other_dfs[name] = df
                with st.expander(f"ä»–æ—¥å ±ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ ({name})", expanded=False):
                    st.dataframe(sanitize_df_for_display(df))

        # Excel
        else:
            engine = "xlrd" if ext == ".xls" else "openpyxl"
            try:
                sheets = pd.read_excel(io.BytesIO(buf), sheet_name=None, engine=engine)
            except Exception as e:
                st.error(f"{name} èª­è¾¼ã‚¨ãƒ©ãƒ¼: {e}")
                continue
            for sheet, sheet_df in sheets.items():
                key = f"{name}:{sheet}"
                try:
                    df_clean = normalize_df(sheet_df)
                    other_dfs[key] = df_clean
                    with st.expander(f"Excelã‚·ãƒ¼ãƒˆãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ ({key})", expanded=False):
                        st.dataframe(sanitize_df_for_display(df_clean))
                except Exception as e:
                    st.error(f"{key} æ­£è¦åŒ–ã‚¨ãƒ©ãƒ¼: {e}")

    if pub_df.empty or not other_dfs:
        st.warning("å…¬é‡‘æ—¥è¨ˆï¼ˆPDFï¼‰ã¨ä»–æ—¥å ±ï¼ˆPDFã¾ãŸã¯Excelï¼‰ãŒä¸¡æ–¹å¿…è¦ã§ã™ã€‚")
        return

    diffs = reconcile_reports(pub_df, other_dfs)
    if diffs:
        st.subheader("ğŸš© å·®ç•°ã‚µãƒãƒªãƒ¼")
        st.table(sanitize_df_for_display(pd.DataFrame(diffs)))
        st.subheader("ğŸ¤– Gemini 2.5ã«ã‚ˆã‚‹åŸå› ç¤ºå”†")
        st.markdown(generate_ai_suggestions(diffs))
    else:
        st.success("ğŸ‰ å·®ç•°ã¯æ¤œå‡ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸã€‚")

if __name__ == "__main__":
    main()
