# app.py

import io
import os
import streamlit as st
import pdfplumber
import pandas as pd
import pytesseract
from pdf2image import convert_from_bytes
import google.generativeai as genai

# â”€â”€â”€ è¨­å®š â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.set_page_config(page_title="FundFlow Advisor", layout="wide")
api_key = st.secrets.get("google", {}).get("api_key")
if not api_key:
    st.error("âŒ `.streamlit/secrets.toml` ã« [google] api_key ã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚")
    st.stop()
genai.configure(api_key=api_key)

# â”€â”€â”€ ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def extract_tables_from_pdf(buf: bytes) -> pd.DataFrame:
    with pdfplumber.open(io.BytesIO(buf)) as pdf:
        tables = [t for p in pdf.pages for t in (p.extract_tables() or [])]
    dfs = [pd.DataFrame(t[1:], columns=t[0]) for t in tables if len(t) > 1]
    return pd.concat(dfs, ignore_index=True) if dfs else pd.DataFrame()

def fallback_ocr_pdf(buf: bytes) -> str:
    imgs = convert_from_bytes(buf)
    return "\n".join(pytesseract.image_to_string(img, lang="jpn") for img in imgs)

def normalize_df(df: pd.DataFrame) -> pd.DataFrame:
    df = df.copy()
    df.columns = [str(c).strip() for c in df.columns]
    for c in df.columns:
        try:
            cleaned = df[c].map(lambda x: str(x).replace(",", "").strip())
            df[c] = pd.to_numeric(cleaned, errors="ignore")
        except Exception:
            st.warning(f"âš ï¸ åˆ— '{c}' ã®æ­£è¦åŒ–ã«å¤±æ•—ã€‚å…ƒã®ã¾ã¾ä¿æŒã—ã¾ã™ã€‚")
    return df

def reconcile_reports(pub: pd.DataFrame, others: dict) -> pd.DataFrame:
    base = pub.select_dtypes(include="number").sum().sum()
    rows = []
    for name, df in others.items():
        s = df.select_dtypes(include="number").sum().sum()
        if base != s:
            rows.append({
                "ãƒ¬ãƒãƒ¼ãƒˆ": name,
                "å…¬é‡‘æ—¥è¨ˆåˆè¨ˆ": base,
                "ä»–æ—¥å ±åˆè¨ˆ": s,
                "å·®ç•°": s - base
            })
    return pd.DataFrame(rows)

def generate_ai_suggestions(df_diff: pd.DataFrame) -> str:
    # DataFrame ã‚’ãƒ—ãƒ¬ãƒ¼ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã§æ¸¡ã™ï¼ˆtabulateä¸è¦ï¼‰
    table_str = df_diff.to_string(index=False)
    prompt = (
        "ä»¥ä¸‹ã®æ—¥å ±çªåˆçµæœã«ã¤ã„ã¦ã€å·®ç•°ã®åŸå› ã‚’ç®‡æ¡æ›¸ãã§ç¤ºã—ã¦ãã ã•ã„ã€‚\n\n"
        + table_str
    )
    resp = genai.chat.completions.create(
        model="gemini-2.5",
        prompt=[{"author": "user", "content": prompt}],
        temperature=0.7
    )
    return resp.candidates[0].message.content

# â”€â”€â”€ ãƒ¡ã‚¤ãƒ³ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def main():
    st.title("FundFlow Advisor ğŸ¦")
    st.markdown(
        "- ã‚µã‚¤ãƒ‰ãƒãƒ¼ã§ **PDF/XLS/XLSX** ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰\n"
        "- ä¸Šéƒ¨ã‚¿ãƒ–ã§ã€Œãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ã€ã€Œå·®ç•°ã‚µãƒãƒªãƒ¼ã€ã€ŒAIç¤ºå”†ã€ã‚’åˆ‡ã‚Šæ›¿ãˆ"
    )

    uploaded = st.sidebar.file_uploader(
        "ğŸ“ ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", type=None, accept_multiple_files=True
    )
    if not uploaded:
        st.sidebar.info("ã“ã“ã§ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")
        return

    pub_df = pd.DataFrame()
    others = {}
    allowed_exts = {".pdf", ".xls", ".xlsx"}

    for f in uploaded:
        name, ext = f.name, os.path.splitext(f.name)[1].lower()
        buf = f.read()
        if ext not in allowed_exts:
            st.sidebar.error(f"{name} ã¯éå¯¾å¿œå½¢å¼ã§ã™ã€‚PDF/XLS/XLSX ã‚’ã”åˆ©ç”¨ãã ã•ã„ã€‚")
            continue

        if ext == ".pdf":
            df = extract_tables_from_pdf(buf)
            if df.empty:
                st.sidebar.warning(f"{name} ã®è¡¨æŠ½å‡ºå¤±æ•—ã€‚OCRçµæœã‚’è¡¨ç¤ºã—ã¾ã™ã€‚")
                st.sidebar.text_area(f"OCR({name})", fallback_ocr_pdf(buf), height=150)
                df = pd.DataFrame()
            df = normalize_df(df)
            if pub_df.empty:
                pub_df = df
            else:
                others[name] = df

        else:
            # .xls ã¯ xlrd, .xlsx ã¯ openpyxl
            engine = "xlrd" if ext == ".xls" else "openpyxl"
            try:
                sheets = pd.read_excel(io.BytesIO(buf), sheet_name=None, engine=engine)
            except Exception as e:
                st.sidebar.error(f"{name} èª­è¾¼ã‚¨ãƒ©ãƒ¼: {e}")
                continue
            for sheet_name, sheet_df in sheets.items():
                key = f"{name}:{sheet_name}"
                others[key] = normalize_df(sheet_df)

    if pub_df.empty or not others:
        st.warning("å…¬é‡‘æ—¥è¨ˆ(PDF) ã¨ ä»–æ—¥å ±(Excel/PDF) ã‚’ãã‚Œãã‚Œ1ä»¶ä»¥ä¸Šå«ã‚ã¦ãã ã•ã„ã€‚")
        return

    df_diff = reconcile_reports(pub_df, others)
    ai_text = generate_ai_suggestions(df_diff) if not df_diff.empty else ""

    tab1, tab2, tab3 = st.tabs(["ğŸ” ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼", "ğŸ“Š å·®ç•°ã‚µãƒãƒªãƒ¼", "ğŸ¤– AIç¤ºå”†"])
    with tab1:
        st.subheader("â—† å…¬é‡‘æ—¥è¨ˆãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼")
        st.code(pub_df.head(10).to_string(index=False), language="")
        for name, df in others.items():
            st.subheader(f"â—† ä»–æ—¥å ±ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ï¼š{name}")
            st.code(df.head(10).to_string(index=False), language="")

    with tab2:
        if df_diff.empty:
            st.success("å·®ç•°ã¯æ¤œå‡ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸã€‚")
        else:
            st.subheader("â—† å·®ç•°ã‚µãƒãƒªãƒ¼")
            st.code(df_diff.to_string(index=False), language="")

    with tab3:
        if df_diff.empty:
            st.info("å·®ç•°ãŒãªã„ãŸã‚ AI ç¤ºå”†ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚")
        else:
            st.subheader("â—† Gemini 2.5 ã«ã‚ˆã‚‹å·®ç•°åŸå› ç¤ºå”†")
            st.markdown(ai_text)

if __name__ == "__main__":
    main()
