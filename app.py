import io, os, re
import streamlit as st
import pdfplumber
import pandas as pd
import pytesseract
from pdf2image import convert_from_bytes
import google.generativeai as genai

# â”€â”€â”€ è¨­å®š â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.set_page_config(page_title="FundFlow Advisor", layout="wide")
api_key = st.secrets.get("google", {}).get("api_key")
if not api_key:
    st.error("âŒ Secrets ã« google.api_key ã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚")
    st.stop()
genai.configure(api_key=api_key)

# â”€â”€â”€ ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def make_unique(cols):
    seen = {}
    out = []
    for c in cols:
        cnt = seen.get(c, 0)
        name = f"{c}.{cnt}" if cnt else c
        seen[c] = cnt + 1
        out.append(name)
    return out

def extract_tables_from_pdf(buf: bytes) -> pd.DataFrame:
    with pdfplumber.open(io.BytesIO(buf)) as pdf:
        tables = []
        for page in pdf.pages:
            for tbl in page.extract_tables() or []:
                if len(tbl) > 1:
                    df = pd.DataFrame(tbl[1:], columns=tbl[0])
                    cols = [str(c).strip() for c in df.columns]
                    df.columns = make_unique(cols)
                    tables.append(df)
    if not tables:
        return pd.DataFrame()
    all_cols = sorted({c for df in tables for c in df.columns})
    aligned = [df.reindex(columns=all_cols) for df in tables]
    return pd.concat(aligned, ignore_index=True, sort=False)

def fallback_ocr_pdf(buf: bytes) -> str:
    imgs = convert_from_bytes(buf)
    return "\n".join(pytesseract.image_to_string(img, lang="jpn") for img in imgs)

def normalize_df(df: pd.DataFrame) -> pd.DataFrame:
    df = df.copy()
    # åˆ—åï¼šå…¨è§’ãƒ»åŠè§’ã‚¹ãƒšãƒ¼ã‚¹é™¤å»
    df.columns = [re.sub(r"\s+", "", str(c)) for c in df.columns]
    for c in df.columns:
        s = (
            df[c]
            .astype(str)
            .map(lambda x: re.sub(r"[^\d\.\-]", "", x))
            .replace({"": pd.NA})
        )
        df[c] = pd.to_numeric(s, errors="ignore")
    df.dropna(axis=0, how="all", inplace=True)
    df.dropna(axis=1, how="all", inplace=True)
    return df

def reconcile_reports(pub: pd.DataFrame, others: dict) -> pd.DataFrame:
    base = pub.select_dtypes(include="number").sum().sum()
    rows = []
    for name, df in others.items():
        total = df.select_dtypes(include="number").sum().sum()
        rows.append({
            "ãƒ¬ãƒãƒ¼ãƒˆ": name,
            "å…¬é‡‘æ—¥è¨ˆåˆè¨ˆ": base,
            "ä»–æ—¥å ±åˆè¨ˆ": total,
            "å·®ç•°": total - base
        })
    return pd.DataFrame(rows)

def analyze_cash_flow(pub: pd.DataFrame) -> tuple[dict, pd.DataFrame]:
    # ã€Œä¼šè¨ˆå‰æ—¥æ®‹é«˜ã€ãŒã‚ã‚Œã°å…ˆé ­è¡Œã§é–‹é–‰ãƒãƒ©ãƒ³ã‚¹ã¨ã—ã¦æŠ½å‡º
    ob = pub["ä¼šè¨ˆå‰æ—¥æ®‹é«˜"].dropna().iloc[0] if "ä¼šè¨ˆå‰æ—¥æ®‹é«˜" in pub.columns else None

    num = pub.select_dtypes(include="number")
    col_sums = num.sum().rename("åˆè¨ˆ").to_frame()

    # å„ªå…ˆåˆ—é¸å®š
    if "å…¥é‡‘" in num.columns and "å‡ºé‡‘" in num.columns:
        inflow = num["å…¥é‡‘"].sum()
        outflow = num["å‡ºé‡‘"].sum()
    elif "åå…¥" in num.columns and "æ”¯å‡º" in num.columns:
        inflow = num["åå…¥"].sum()
        outflow = num["æ”¯å‡º"].sum()
    elif "æœˆè¨ˆåæ”¯" in num.columns:
        # æœˆè¨ˆåæ”¯ = åå…¥-æ”¯å‡º ã¨ä»®å®š
        inflow = num["æœˆè¨ˆåæ”¯"][num["æœˆè¨ˆåæ”¯"] > 0].sum()
        outflow = -num["æœˆè¨ˆåæ”¯"][num["æœˆè¨ˆåæ”¯"] < 0].sum()
    else:
        inflow = num[num>0].sum().sum()
        outflow = -num[num<0].sum().sum()

    net = inflow - outflow
    metrics = {"å§‹å€¤(å‰æ—¥æ®‹é«˜)": ob, "ç·æµå…¥": inflow, "ç·æµå‡º": outflow, "ç´”å¢—æ¸›": net}
    return metrics, col_sums

def generate_ai_suggestions(df_diff: pd.DataFrame) -> str:
    table = df_diff[df_diff["å·®ç•°"] != 0].to_string(index=False) or "ï¼ˆå…¨ãƒ¬ãƒãƒ¼ãƒˆå·®ç•°ãªã—ï¼‰"
    prompt = (
        "ä»¥ä¸‹ã®å·®ç•°ã«ã¤ã„ã¦ã€åŸå› ã‚’ç®‡æ¡æ›¸ãã§ç¤ºã—ã¦ãã ã•ã„ã€‚\n\n"
        + table
    )
    resp = genai.chat.completions.create(
        model="gemini-2.5",
        prompt=[{"author":"user","content":prompt}],
        temperature=0.7
    )
    return resp.candidates[0].message.content

# â”€â”€â”€ UI â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def main():
    st.title("FundFlow Advisor ğŸ¦")
    st.markdown(
        "- ã‚µã‚¤ãƒ‰ãƒãƒ¼ã§PDFã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰\n"
        "- ä¸Šéƒ¨ã‚¿ãƒ–ã§ã€Œãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ã€ã€Œå·®ç•°ã‚µãƒãƒªãƒ¼ã€ã€Œåˆ†æã€ã€ŒAIç¤ºå”†ã€"
    )

    uploaded = st.sidebar.file_uploader(
        "ğŸ“ å…¬é‡‘æ—¥è¨ˆPDF ã¨ ä»–æ—¥å ±PDF", type=None, accept_multiple_files=True
    )
    if not uploaded:
        st.sidebar.info("ã“ã“ã§PDFã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")
        return

    pub_df, others = pd.DataFrame(), {}
    for f in uploaded:
        if not f.name.lower().endswith(".pdf"):
            st.sidebar.error(f"{f.name} ã¯PDFã§ã¯ã‚ã‚Šã¾ã›ã‚“")
            continue
        buf = f.read()
        df = extract_tables_from_pdf(buf)
        if df.empty:
            st.sidebar.warning(f"{f.name} æŠ½å‡ºå¤±æ•—ã€‚OCRã‚’è¡¨ç¤º")
            st.sidebar.text_area(f"OCR({f.name})", fallback_ocr_pdf(buf), height=150)
            continue
        df = normalize_df(df)
        if pub_df.empty:
            pub_df = df; st.sidebar.success(f"{f.name} ã‚’åŸºæº–ã«è¨­å®š")
        else:
            others[f.name] = df; st.sidebar.success(f"{f.name} ã‚’ä»–æ—¥å ±ã«è¿½åŠ ")

    if pub_df.empty or not others:
        st.warning("åŸºæº–ã¨ä»–æ—¥å ±ã€ä¸¡æ–¹ã®PDFãŒå¿…è¦ã§ã™ã€‚")
        return

    df_diff = reconcile_reports(pub_df, others)
    cash_metrics, col_sums = analyze_cash_flow(pub_df)
    ai_text = generate_ai_suggestions(df_diff)

    tab1, tab2, tab3, tab4 = st.tabs(
        ["ğŸ” ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼", "ğŸ“Š å·®ç•°ã‚µãƒãƒªãƒ¼", "ğŸ’¡ åˆ†æ", "ğŸ¤– AIç¤ºå”†"]
    )

    with tab1:
        st.subheader("â–  å…¬é‡‘æ—¥è¨ˆãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼")
        st.write("**åˆ—åä¸€è¦§(æ­£è¦åŒ–å¾Œ)**", list(pub_df.columns))
        st.dataframe(pub_df, use_container_width=True)
        for name, df in others.items():
            st.subheader(f"â–  ä»–æ—¥å ±ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ï¼š{name}")
            st.dataframe(df, use_container_width=True)

    with tab2:
        st.subheader("â–  å·®ç•°ã‚µãƒãƒªãƒ¼")
        st.dataframe(df_diff, use_container_width=True)

    with tab3:
        st.subheader("â–  ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ•ãƒ­ãƒ¼ï¼åˆ—åˆè¨ˆåˆ†æ")
        # å‰æ—¥æ®‹é«˜
        if cash_metrics["å§‹å€¤(å‰æ—¥æ®‹é«˜)"] is not None:
            st.metric("å‰æ—¥æ®‹é«˜", f"{int(cash_metrics['å§‹å€¤(å‰æ—¥æ®‹é«˜)']):,}")
        # æµå…¥ãƒ»æµå‡ºãƒ»ç´”å¢—æ¸›
        c1, c2, c3 = st.columns(3)
        c1.metric("ç·æµå…¥", f"{int(cash_metrics['ç·æµå…¥']):,}")
        c2.metric("ç·æµå‡º", f"{int(cash_metrics['ç·æµå‡º']):,}")
        c3.metric("ç´”å¢—æ¸›", f"{int(cash_metrics['ç´”å¢—æ¸›']):,}")
        st.subheader("â—¾ åˆ—ã”ã¨ã®åˆè¨ˆå€¤")
        st.dataframe(col_sums, use_container_width=True)
        # ãƒªã‚¹ã‚¯åˆ¤å®š
        if cash_metrics["ç´”å¢—æ¸›"] < 0:
            st.error("âš ï¸ è³‡é‡‘ã‚·ãƒ§ãƒ¼ãƒˆã®ãƒªã‚¹ã‚¯ãŒã‚ã‚Šã¾ã™ã€‚")
        elif cash_metrics["ç´”å¢—æ¸›"] < cash_metrics["ç·æµå‡º"] * 0.1:
            st.warning("âš ï¸ è³‡é‡‘ä½™è£•ãŒä¹ã—ã„å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚")
        else:
            st.success("âœ… ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒã‚¸ã‚·ãƒ§ãƒ³ã¯å¥å…¨ã§ã™ã€‚")

    with tab4:
        st.subheader("â–  å·®ç•°åŸå› ç¤ºå”† (Gemini 2.5)")
        st.markdown(ai_text)

if __name__ == "__main__":
    main()
