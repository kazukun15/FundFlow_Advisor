import io, re
import streamlit as st
import pdfplumber
import pandas as pd
import pytesseract
from pdf2image import convert_from_bytes
import google.generativeai as genai

# â”€â”€â”€ Secrets ã‹ã‚‰ APIã‚­ãƒ¼å–å¾— â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if "google" not in st.secrets or "api_key" not in st.secrets["google"]:
    st.error('`.streamlit/secrets.toml` ã«ä»¥ä¸‹ã‚’ç™»éŒ²ã—ã¦ãã ã•ã„:\n\n'
             '[google]\n'
             'api_key = "YOUR_GOOGLE_API_KEY"')
    st.stop()
genai.configure(api_key=st.secrets["google"]["api_key"])

# â”€â”€â”€ æ—¥ä»˜æŠ½å‡ºãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def extract_date_from_filename(name: str) -> str:
    # YYYY-MM-DD, YYYY_MM_DD, YYYYMMDD ãªã©ã«å¯¾å¿œ
    m = re.search(r'(\d{4})[-_]?(\d{1,2})[-_]?(\d{1,2})', name)
    if m:
        y, mo, d = m.group(1), m.group(2), m.group(3)
        return f"{y}-{int(mo):02d}-{int(d):02d}"
    return "ãã®ä»–"

# â”€â”€â”€ PDF ãƒ†ãƒ¼ãƒ–ãƒ«æŠ½å‡ºï¼OCRï¼æ­£è¦åŒ– â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def make_unique(cols):
    seen = {}; out=[]
    for c in cols:
        cnt = seen.get(c,0)
        name = f"{c}.{cnt}" if cnt else c
        seen[c]=cnt+1; out.append(name)
    return out

def extract_tables_from_pdf(buf: bytes) -> pd.DataFrame:
    with pdfplumber.open(io.BytesIO(buf)) as pdf:
        tbls=[]
        for p in pdf.pages:
            for t in p.extract_tables() or []:
                if len(t)>1:
                    df=pd.DataFrame(t[1:],columns=t[0])
                    df.columns=make_unique([str(c).strip() for c in df.columns])
                    tbls.append(df)
    if not tbls: return pd.DataFrame()
    cols=sorted({c for df in tbls for c in df.columns})
    aligned=[df.reindex(columns=cols) for df in tbls]
    return pd.concat(aligned,ignore_index=True,sort=False)

def ocr_text(buf: bytes)->str:
    imgs=convert_from_bytes(buf)
    return "\n".join(pytesseract.image_to_string(i,lang="jpn") for i in imgs)

def normalize_df(df: pd.DataFrame)->pd.DataFrame:
    df=df.copy()
    df.columns=[re.sub(r"\s+","",str(c)) for c in df.columns]
    for c in df.columns:
        s=(df[c].astype(str)
             .map(lambda x: re.sub(r"[^\d\.\-]","",x))
             .replace({"":pd.NA}))
        df[c]=pd.to_numeric(s,errors="ignore")
    df.dropna(axis=0,how="all",inplace=True)
    df.dropna(axis=1,how="all",inplace=True)
    return df

# â”€â”€â”€ çªåˆãƒ»ã‚­ãƒ£ãƒƒã‚·ãƒ¥åˆ†æãƒ»AIææ¡ˆ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def reconcile(pub:pd.DataFrame, others:dict)->pd.DataFrame:
    base=pub.select_dtypes("number").sum().sum()
    rows=[]
    for name,df in others.items():
        tot=df.select_dtypes("number").sum().sum()
        rows.append({"ãƒ¬ãƒãƒ¼ãƒˆ":name,"å…¬é‡‘æ—¥è¨ˆåˆè¨ˆ":base,"ä»–æ—¥å ±åˆè¨ˆ":tot,"å·®ç•°":tot-base})
    return pd.DataFrame(rows)

def analyze_cf(pub:pd.DataFrame):
    ob=pub.get("ä¼šè¨ˆå‰æ—¥æ®‹é«˜",pd.Series(dtype=float)).dropna()
    ob=ob.iloc[0] if not ob.empty else None
    nums=pub.select_dtypes("number")
    sums=nums.sum().rename("åˆè¨ˆ").to_frame()
    if {"å…¥é‡‘","å‡ºé‡‘"}.issubset(nums.columns):
        infl, outf=nums["å…¥é‡‘"].sum(), nums["å‡ºé‡‘"].sum()
    elif {"åå…¥","æ”¯å‡º"}.issubset(nums.columns):
        infl, outf=nums["åå…¥"].sum(), nums["æ”¯å‡º"].sum()
    else:
        infl=nums[nums>0].sum().sum(); outf=-nums[nums<0].sum().sum()
    net=infl-outf
    return {"å‰æ—¥æ®‹é«˜":ob,"ç·æµå…¥":infl,"ç·æµå‡º":outf,"ç´”å¢—æ¸›":net}, sums

def ai_suggest(df_diff:pd.DataFrame)->str:
    diff=df_diff[df_diff["å·®ç•°"]!=0]
    txt=diff.to_string(index=False) if not diff.empty else "ï¼ˆå·®ç•°ãªã—ï¼‰"
    prompt=f"ä»¥ä¸‹ã®å·®ç•°ã«ã¤ã„ã¦ã€åŸå› ã‚’ç®‡æ¡æ›¸ãã§ç¤ºã—ã¦ãã ã•ã„ã€‚\n\n{txt}"
    try:
        model=genai.GenerativeModel("gemini-2.5-flash-preview-04-17")
        resp=model.generate_content(prompt)
        if hasattr(resp,"text") and resp.text:
            return resp.text.strip()
        if hasattr(resp,"parts"):
            return "".join(p.text for p in resp.parts).strip()
        st.warning("AIå¿œç­”å½¢å¼ãŒäºˆæœŸã›ã¬ã‚‚ã®ã§ã—ãŸã€‚")
        return "AIã‹ã‚‰ææ¡ˆã‚’å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚"
    except Exception as e:
        st.error(f"AIææ¡ˆç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
        return "AIææ¡ˆç”Ÿæˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚"

# â”€â”€â”€ Streamlit UI â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def main():
    st.set_page_config(page_title="FundFlow Advisor AI", layout="wide")
    st.title("FundFlow Advisor AI")
    st.markdown("PDFã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã€æœˆå†…ã®ãã®ä»–æ—¥å ±ã‚’æ—¥ä»˜ã”ã¨ã«æŠ˜ã‚ŠãŸãŸã‚“ã§è¡¨ç¤ºã—ã¾ã™ã€‚")

    files=st.sidebar.file_uploader(
        "ğŸ“ å…¬é‡‘æ—¥è¨ˆPDF ã¨ ä»–æ—¥å ±PDFä¸€è¦§", type=None, accept_multiple_files=True
    )
    if not files:
        st.sidebar.info("ã“ã“ã«PDFã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")
        return

    # å…¬é‡‘æ—¥è¨ˆã¯æœ€åˆã®PDFã€ãã‚Œä»¥å¤–ã‚’monthly_reportsã«
    pub_df=pd.DataFrame()
    monthly_reports={}
    for f in files:
        if not f.name.lower().endswith(".pdf"):
            st.sidebar.error(f"{f.name} ã¯PDFã§ã¯ã‚ã‚Šã¾ã›ã‚“"); continue
        buf=f.read(); df=extract_tables_from_pdf(buf)
        if df.empty:
            st.sidebar.warning(f"{f.name} ã®è¡¨æŠ½å‡ºå¤±æ•—â†’OCRè¡¨ç¤º")
            st.sidebar.text_area(f"OCR({f.name})",ocr_text(buf),height=150)
            continue
        df=normalize_df(df)
        if pub_df.empty:
            pub_df=df; st.sidebar.success(f"{f.name} ã‚’åŸºæº–ã«è¨­å®š")
        else:
            date_key=extract_date_from_filename(f.name)
            monthly_reports.setdefault(date_key,[]).append((f.name,df))
            st.sidebar.success(f"{f.name} ã‚’æ—¥ä»˜ {date_key} ã«è¿½åŠ ")

    if pub_df.empty or not monthly_reports:
        st.warning("å…¬é‡‘æ—¥è¨ˆPDFã¨ãã®ä»–æ—¥å ±PDF(æœˆå†…)ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")
        return

    df_diff=reconcile(pub_df, {n:d for lst in monthly_reports.values() for n,d in lst})
    cf_metrics,cf_sums=analyze_cf(pub_df)
    ai_text=ai_suggest(df_diff)

    tab1,tab2,tab3,tab4=st.tabs(["ğŸ” ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼","ğŸ“Š å·®ç•°ã‚µãƒãƒªãƒ¼","ğŸ’¡ åˆ†æ","ğŸ¤– AIææ¡ˆ"])
    with tab1:
        st.subheader("â–  å…¬é‡‘æ—¥è¨ˆãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼")
        st.dataframe(pub_df,use_container_width=True)
        st.markdown("### â–  ãã®ä»–æ—¥å ±ï¼ˆæœˆå†…ï¼‰")
        for date,items in sorted(monthly_reports.items()):
            with st.expander(f"â–¶ {date} ({len(items)}ä»¶)", expanded=False):
                for name,df in items:
                    st.write(f"**{name}**")
                    st.dataframe(df,use_container_width=True)
    with tab2:
        st.subheader("â–  å·®ç•°ã‚µãƒãƒªãƒ¼")
        st.dataframe(df_diff,use_container_width=True)
    with tab3:
        st.subheader("â–  ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ•ãƒ­ãƒ¼åˆ†æ")
        if cf_metrics["å‰æ—¥æ®‹é«˜"] is not None:
            st.metric("å‰æ—¥æ®‹é«˜",f"{int(cf_metrics['å‰æ—¥æ®‹é«˜']):,}")
        c1,c2,c3=st.columns(3)
        c1.metric("ç·æµå…¥",f"{int(cf_metrics['ç·æµå…¥']):,}")
        c2.metric("ç·æµå‡º",f"{int(cf_metrics['ç·æµå‡º']):,}")
        c3.metric("ç´”å¢—æ¸›",f"{int(cf_metrics['ç´”å¢—æ¸›']):,}")
        st.subheader("â–ª åˆ—åˆè¨ˆãƒ‡ãƒãƒƒã‚°")
        st.dataframe(cf_sums,use_container_width=True)
        if cf_metrics["ç´”å¢—æ¸›"]<0:
            st.error("âš ï¸ è³‡é‡‘ã‚·ãƒ§ãƒ¼ãƒˆãƒªã‚¹ã‚¯")
        elif cf_metrics["ç´”å¢—æ¸›"]<cf_metrics["ç·æµå‡º"]*0.1:
            st.warning("âš ï¸ è³‡é‡‘ä½™è£•ãŒä¹ã—ã„å¯èƒ½æ€§")
        else:
            st.success("âœ… ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒã‚¸ã‚·ãƒ§ãƒ³ã¯å¥å…¨ã§ã™")
    with tab4:
        st.subheader("â–  AIã«ã‚ˆã‚‹åŸå› ææ¡ˆ")
        st.markdown(ai_text)

if __name__=="__main__":
    main()
