# Write the updated requirements.txt
requirements_txt = """\
streamlit
pdfplumber
pytesseract
pdf2image
pillow
pandas
openai
"""

with open('/mnt/data/requirements.txt', 'w') as f:
    f.write(requirements_txt)

# Write the updated app code with Gemini 2.5 model
app_code = """import streamlit as st
import pdfplumber
import pandas as pd
import pytesseract
from pdf2image import convert_from_bytes
from PIL import Image
import io
import openai

# --- è¨­å®š ---
openai.api_key = st.secrets["openai"]["api_key"]

# --- PDFæŠ½å‡ºé–¢æ•° ---
def extract_tables_from_pdf(file_bytes):
    \"\"\"PDFã‹ã‚‰ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’æŠ½å‡ºã—ã¦DataFrameã¨ã—ã¦è¿”ã™\"\"\"
    with pdfplumber.open(io.BytesIO(file_bytes)) as pdf:
        tables = []
        for page in pdf.pages:
            tables.extend(page.extract_tables())
    dfs = []
    for table in tables:
        if table and len(table) > 1:
            df = pd.DataFrame(table[1:], columns=table[0])
            dfs.append(df)
    if dfs:
        return pd.concat(dfs, ignore_index=True)
    return pd.DataFrame()

def fallback_ocr_pdf(file_bytes):
    \"\"\"OCRã§PDFã‚’ç”»åƒåŒ–ã—ã€ãƒ†ã‚­ã‚¹ãƒˆã‚’æŠ½å‡º\"\"\"
    images = convert_from_bytes(file_bytes)
    text = ""
    for img in images:
        text += pytesseract.image_to_string(img, lang='jpn')
    return text

# --- æ­£è¦åŒ–é–¢æ•° ---
def normalize_df(df):
    \"\"\"æ•°å€¤ã‚«ãƒ©ãƒ ã‚’æ­£ã—ãèªè­˜ã•ã›ã‚‹ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°å‡¦ç†\"\"\"
    df = df.copy()
    df.columns = df.columns.str.strip()
    for col in df.columns:
        if df[col].dtype == object:
            df[col] = df[col].str.replace(',', '').str.strip()
        try:
            df[col] = pd.to_numeric(df[col])
        except:
            pass
    return df

# --- çªåˆé–¢æ•° ---
def reconcile_reports(pub_df, other_dfs):
    \"\"\"å…¬é‡‘æ—¥è¨ˆã¨ä»–æ—¥å ±ã‚’æ¯”è¼ƒã—ã€å·®ç•°ã‚’ã¾ã¨ã‚ã‚‹\"\"\"
    pub_sum = pub_df['é‡‘é¡'].sum() if 'é‡‘é¡' in pub_df.columns else pub_df.select_dtypes(include='number').sum().sum()
    suggestions = []
    for name, df in other_dfs.items():
        df_sum = df['é‡‘é¡'].sum() if 'é‡‘é¡' in df.columns else df.select_dtypes(include='number').sum().sum()
        if pub_sum != df_sum:
            suggestions.append({
                'ãƒ¬ãƒãƒ¼ãƒˆ': name,
                'å…¬é‡‘æ—¥è¨ˆåˆè¨ˆ': pub_sum,
                'ä»–æ—¥å ±åˆè¨ˆ': df_sum,
                'å·®ç•°': df_sum - pub_sum
            })
    return suggestions

# --- AIç¤ºå”†ç”Ÿæˆé–¢æ•° ---
def generate_ai_suggestions(suggestions):
    \"\"\"å·®ç•°æƒ…å ±ã‚’ã‚‚ã¨ã«åŸå› ç¤ºå”†ã‚’AIã«ç”Ÿæˆã•ã›ã‚‹\"\"\"
    prompt = (
        "ä»¥ä¸‹ã®æ—¥å ±çªåˆçµæœã«ã¤ã„ã¦ã€"
        "ãªãœå·®ç•°ãŒç™ºç”Ÿã—ãŸã‹ã®å¯èƒ½æ€§ã‚’ç®‡æ¡æ›¸ãã§ç¤ºå”†ã—ã¦ãã ã•ã„ã€‚\\n"
        f"{suggestions}"
    )
    response = openai.ChatCompletion.create(
        model='gemini-2.5',
        messages=[{"role": "user", "content": prompt}],
        temperature=0.7
    )
    return response.choices[0].message.content

# --- Streamlit UI ---
def main():
    st.title("ğŸ—’ æ—¥å ±ä½œæˆæ”¯æ´ã‚¢ãƒ—ãƒª")
    st.markdown("å…¬é‡‘æ—¥è¨ˆPDFã¨å„éƒ¨ç½²ã®æ—¥å ±PDFã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã€çªåˆã‚„AIç¤ºå”†ã‚’è¡Œã„ã¾ã™ã€‚")

    pub_file = st.file_uploader("ğŸ“‘ å…¬é‡‘æ—¥è¨ˆPDFã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", type=['pdf'])
    other_files = st.file_uploader("ğŸ“‘ ä»–éƒ¨ç½²æ—¥å ±PDFã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ï¼ˆè¤‡æ•°å¯ï¼‰", type=['pdf'], accept_multiple_files=True)

    if pub_file and other_files:
        # å…¬é‡‘æ—¥è¨ˆPDFè§£æ
        bytes_pub = pub_file.read()
        try:
            pub_df = extract_tables_from_pdf(bytes_pub)
            st.success("âœ… å…¬é‡‘æ—¥è¨ˆPDFã®ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’æŠ½å‡ºã—ã¾ã—ãŸã€‚")
        except Exception:
            st.warning("âš ï¸ ãƒ†ãƒ¼ãƒ–ãƒ«æŠ½å‡ºã«å¤±æ•—ã—ãŸãŸã‚OCRã‚’å®Ÿè¡Œã—ã¾ã™ã€‚")
            text = fallback_ocr_pdf(bytes_pub)
            st.text_area("OCRãƒ†ã‚­ã‚¹ãƒˆï¼ˆå…¬é‡‘æ—¥è¨ˆï¼‰", text, height=200)
            pub_df = pd.DataFrame()  # OCRçµæœã¯æ‰‹å‹•ç¢ºèªç”¨

        pub_df = normalize_df(pub_df)

        # ä»–æ—¥å ±PDFè§£æ
        other_dfs = {}
        for f in other_files:
            bytes_f = f.read()
            try:
                df = extract_tables_from_pdf(bytes_f)
                st.success(f"âœ… {f.name} ã®ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’æŠ½å‡ºã—ã¾ã—ãŸã€‚")
            except Exception:
                st.warning(f"âš ï¸ {f.name} ã¯ãƒ†ãƒ¼ãƒ–ãƒ«æŠ½å‡ºã«å¤±æ•—ã€‚OCRã‚’è¡¨ç¤ºã—ã¾ã™ã€‚")
                text = fallback_ocr_pdf(bytes_f)
                st.text_area(f"OCRãƒ†ã‚­ã‚¹ãƒˆï¼ˆ{f.name}ï¼‰", text, height=200)
                df = pd.DataFrame()
            other_dfs[f.name] = normalize_df(df)

        # å·®ç•°è¨ˆç®—ã¨è¡¨ç¤º
        suggestions = reconcile_reports(pub_df, other_dfs)
        if suggestions:
            st.subheader("â–¶ å·®ç•°ã‚µãƒãƒª")
            st.table(pd.DataFrame(suggestions))
            st.subheader("â–¶ AIã‹ã‚‰ã®åŸå› ç¤ºå”†")
            ai_text = generate_ai_suggestions(suggestions)
            st.write(ai_text)
        else:
            st.success("ğŸ‰ æ—¥å ±é–“ã«å·®ç•°ã¯æ¤œå‡ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸã€‚")
    else:
        st.info("ã¾ãšã¯ã™ã¹ã¦ã®PDFã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")

if __name__ == "__main__":
    main()
"""

with open('/mnt/data/app_updated.py', 'w') as f:
    f.write(app_code)

# Display links for download
print("[Download requirements.txt](sandbox:/mnt/data/requirements.txt)")
print("[Download updated app code](sandbox:/mnt/data/app_updated.py)")
