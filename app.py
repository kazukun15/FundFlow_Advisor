import io
import streamlit as st
import pdfplumber
import pandas as pd
import pytesseract
from pdf2image import convert_from_bytes
import google.generativeai as genai

# â”€â”€â”€ Google API Key è¨­å®šï¼ˆSecretsï¼‰ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
api_key = st.secrets.get("google", {}).get("api_key")
if not api_key:
    st.error("âŒ .streamlit/secrets.toml ã® [google] api_key ã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚")
    st.stop()
genai.configure(api_key=api_key)

# â”€â”€â”€ PDFè§£æé–¢æ•° â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def extract_tables_from_pdf(file_bytes: bytes) -> pd.DataFrame:
    with pdfplumber.open(io.BytesIO(file_bytes)) as pdf:
        tables = [tbl for page in pdf.pages for tbl in (page.extract_tables() or [])]
    dfs = [pd.DataFrame(tbl[1:], columns=tbl[0]) for tbl in tables if len(tbl) > 1]
    return pd.concat(dfs, ignore_index=True) if dfs else pd.DataFrame()

def fallback_ocr_pdf(file_bytes: bytes) -> str:
    images = convert_from_bytes(file_bytes)
    text = ""
    for img in images:
        text += pytesseract.image_to_string(img, lang="jpn")
    return text

# â”€â”€â”€ ãƒ‡ãƒ¼ã‚¿æ­£è¦åŒ–é–¢æ•° â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def normalize_df(df: pd.DataFrame) -> pd.DataFrame:
    df = df.copy()
    df.columns = df.columns.str.strip()
    for col in df.columns:
        if df[col].dtype == object:
            df[col] = df[col].str.replace(",", "").str.strip()
        try:
            df[col] = pd.to_numeric(df[col])
        except:
            pass
    return df

# â”€â”€â”€ çªåˆãƒ­ã‚¸ãƒƒã‚¯ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def reconcile_reports(pub_df: pd.DataFrame, other_dfs: dict) -> list[dict]:
    pub_sum = (
        pub_df["é‡‘é¡"].sum()
        if "é‡‘é¡" in pub_df.columns
        else pub_df.select_dtypes(include="number").sum().sum()
    )
    results = []
    for name, df in other_dfs.items():
        df_sum = (
            df["é‡‘é¡"].sum()
            if "é‡‘é¡" in df.columns
            else df.select_dtypes(include="number").sum().sum()
        )
        if pub_sum != df_sum:
            results.append({
                "ãƒ¬ãƒãƒ¼ãƒˆ": name,
                "å…¬é‡‘æ—¥è¨ˆåˆè¨ˆ": pub_sum,
                "ä»–æ—¥å ±åˆè¨ˆ": df_sum,
                "å·®ç•°": df_sum - pub_sum
            })
    return results

# â”€â”€â”€ AIç¤ºå”†ç”Ÿæˆé–¢æ•° â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def generate_ai_suggestions(suggestions: list[dict]) -> str:
    df = pd.DataFrame(suggestions)
    prompt = (
        "ä»¥ä¸‹ã®æ—¥å ±çªåˆçµæœã«ã¤ã„ã¦ã€å·®ç•°ã®åŸå› ã‚’ç®‡æ¡æ›¸ãã§ç¤ºã—ã¦ãã ã•ã„ã€‚\n\n"
        + df.to_markdown(index=False)
    )
    response = genai.chat.completions.create(
        model="gemini-2.5",
        prompt=[{"author": "user", "content": prompt}],
        temperature=0.7
    )
    return response.candidates[0].message.content

# â”€â”€â”€ Streamlit UI â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def main():
    st.set_page_config(page_title="FundFlow Advisor", layout="wide")
    st.title("FundFlow Advisor")
    st.markdown(
        "å…¬é‡‘æ—¥è¨ˆPDFã¨å„éƒ¨ç½²æ—¥å ±PDFã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã€"
        "å·®ç•°çªåˆçµæœã¨ Gemini 2.5 ã«ã‚ˆã‚‹åŸå› ç¤ºå”†ã‚’è¡Œã„ã¾ã™ã€‚"
    )

    # typeåˆ¶é™ãªã—ã§ã¾ãšã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
    pub_file = st.file_uploader("ğŸ“‘ å…¬é‡‘æ—¥è¨ˆPDFã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", type=None)
    other_files = st.file_uploader(
        "ğŸ“‘ ä»–éƒ¨ç½²æ—¥å ±PDFã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ï¼ˆè¤‡æ•°å¯ï¼‰", 
        type=None, 
        accept_multiple_files=True
    )

    # å…¥åŠ›ãƒã‚§ãƒƒã‚¯
    if not pub_file or not other_files:
        st.info("ã¾ãšä¸¡æ–¹ã®PDFã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")
        return

    # ãƒ•ã‚¡ã‚¤ãƒ«åæ‹¡å¼µå­ãƒã‚§ãƒƒã‚¯
    if not pub_file.name.lower().endswith(".pdf"):
        st.error("å…¬é‡‘æ—¥è¨ˆãƒ•ã‚¡ã‚¤ãƒ«ã¯PDFå½¢å¼(.pdf)ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")
        return
    for f in other_files:
        if not f.name.lower().endswith(".pdf"):
            st.error(f"ã€Œ{f.name}ã€ã¯PDFå½¢å¼(.pdf)ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚")
            return

    # å…¬é‡‘æ—¥è¨ˆè§£æ
    pub_bytes = pub_file.read()
    df_pub = extract_tables_from_pdf(pub_bytes)
    if df_pub.empty:
        st.warning("å…¬é‡‘æ—¥è¨ˆã®ãƒ†ãƒ¼ãƒ–ãƒ«æŠ½å‡ºã«å¤±æ•—ã—ã¾ã—ãŸã€‚OCRçµæœã‚’ã”ç¢ºèªãã ã•ã„ã€‚")
        st.text_area("OCRï¼ˆå…¬é‡‘æ—¥è¨ˆï¼‰", fallback_ocr_pdf(pub_bytes), height=200)
    df_pub = normalize_df(df_pub)
    st.subheader("å…¬é‡‘æ—¥è¨ˆãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼")
    st.dataframe(df_pub)

    # ä»–éƒ¨ç½²æ—¥å ±è§£æ
    other_dfs = {}
    for f in other_files:
        buf = f.read()
        df = extract_tables_from_pdf(buf)
        if df.empty:
            st.warning(f"{f.name} ã®æŠ½å‡ºã«å¤±æ•—ã€‚OCRçµæœã‚’è¡¨ç¤ºã—ã¾ã™ã€‚")
            st.text_area(f"OCRï¼ˆ{f.name}ï¼‰", fallback_ocr_pdf(buf), height=200)
        df = normalize_df(df)
        other_dfs[f.name] = df
        st.subheader(f"{f.name} ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼")
        st.dataframe(df)

    # çªåˆï¼†AIç¤ºå”†
    diffs = reconcile_reports(df_pub, other_dfs)
    if diffs:
        st.subheader("â–¶ å·®ç•°ã‚µãƒãƒª")
        st.table(pd.DataFrame(diffs))
        st.subheader("â–¶ Gemini 2.5 ã«ã‚ˆã‚‹åŸå› ç¤ºå”†")
        suggestion = generate_ai_suggestions(diffs)
        st.markdown(suggestion)
    else:
        st.success("ğŸ‰ å·®ç•°ã¯æ¤œå‡ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸã€‚")

if __name__ == "__main__":
    main()
