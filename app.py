import io, os
import streamlit as st
import pdfplumber
import pandas as pd
import pytesseract
from pdf2image import convert_from_bytes
import google.generativeai as genai

# â”€â”€â”€ Google API Key è¨­å®šï¼ˆSecretsï¼‰â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
api_key = st.secrets.get("google", {}).get("api_key")
if not api_key:
    st.error("âŒ `.streamlit/secrets.toml` ã® [google] api_key ã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚")
    st.stop()
genai.configure(api_key=api_key)

# â”€â”€â”€ PDFè§£æ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def extract_tables_from_pdf(file_bytes: bytes) -> pd.DataFrame:
    with pdfplumber.open(io.BytesIO(file_bytes)) as pdf:
        tables = [tbl for page in pdf.pages for tbl in (page.extract_tables() or [])]
    dfs = [pd.DataFrame(tbl[1:], columns=tbl[0]) for tbl in tables if len(tbl) > 1]
    return pd.concat(dfs, ignore_index=True) if dfs else pd.DataFrame()

def fallback_ocr_pdf(file_bytes: bytes) -> str:
    images = convert_from_bytes(file_bytes)
    return "".join(pytesseract.image_to_string(img, lang="jpn") for img in images)

# â”€â”€â”€ ãƒ‡ãƒ¼ã‚¿æ­£è¦åŒ–ï¼ˆå®‰å…¨ç‰ˆï¼‰ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def normalize_df(df: pd.DataFrame) -> pd.DataFrame:
    """
    ãƒ»åˆ—åã‚’ã™ã¹ã¦æ–‡å­—åˆ—åŒ–ã—ã¦ strip
    ãƒ»å„ã‚»ãƒ«ã‚’ map() ã§æ–‡å­—åˆ—åŒ–â†’ã‚«ãƒ³ãƒé™¤å»â†’trimâ†’æ•°å€¤å¤‰æ›
    """
    df = df.copy()
    # åˆ—åã‚’ str åŒ–ã—ã¦ strip
    df.columns = [str(col).strip() for col in df.columns]
    for col in df.columns:
        # map ã§è¦ç´ å˜ä½ã«å‡¦ç†
        cleaned = df[col].map(lambda x: str(x).replace(",", "").strip())
        # æ•°å€¤å¤‰æ›ï¼ˆã§ããªã„ã‚‚ã®ã¯å…ƒã®æ–‡å­—åˆ—ï¼‰
        df[col] = pd.to_numeric(cleaned, errors="ignore")
    return df

# â”€â”€â”€ è¡¨ç¤ºã‚µãƒ‹ã‚¿ã‚¤ã‚º â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def sanitize_df_for_display(df: pd.DataFrame) -> pd.DataFrame:
    df = df.copy()
    for col in df.columns:
        if df[col].dtype == object:
            df[col] = df[col].map(lambda x: x if isinstance(x, (str, int, float, bool, type(None))) else str(x))
    return df

# â”€â”€â”€ çªåˆãƒ­ã‚¸ãƒƒã‚¯ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def reconcile_reports(pub_df: pd.DataFrame, other_dfs: dict) -> list[dict]:
    pub_sum = (
        pub_df.get("é‡‘é¡", pd.Series(dtype=float)).sum()
        if "é‡‘é¡" in pub_df.columns
        else pub_df.select_dtypes(include="number").sum().sum()
    )
    results = []
    for name, df in other_dfs.items():
        df_sum = (
            df.get("é‡‘é¡", pd.Series(dtype=float)).sum()
            if "é‡‘é¡" in df.columns
            else df.select_dtypes(include="number").sum().sum()
        )
        if pub_sum != df_sum:
            results.append({
                "ãƒ¬ãƒãƒ¼ãƒˆ": name,
                "å…¬é‡‘æ—¥è¨ˆåˆè¨ˆ": pub_sum,
                "ä»–æ—¥å ±åˆè¨ˆ": df_sum,
                "å·®ç•°": df_sum - pub_sum
            })
    return results

# â”€â”€â”€ AIç¤ºå”†ç”Ÿæˆ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def generate_ai_suggestions(suggestions: list[dict]) -> str:
    df = pd.DataFrame(suggestions)
    prompt = (
        "ä»¥ä¸‹ã®æ—¥å ±çªåˆçµæœã«ã¤ã„ã¦ã€å·®ç•°ã®åŸå› ã‚’ç®‡æ¡æ›¸ãã§ç¤ºã—ã¦ãã ã•ã„ã€‚\n\n"
        + df.to_markdown(index=False)
    )
    response = genai.chat.completions.create(
        model="gemini-2.5",
        prompt=[{"author": "user", "content": prompt}],
        temperature=0.7
    )
    return response.candidates[0].message.content

# â”€â”€â”€ Streamlit UI â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def main():
    st.set_page_config(page_title="FundFlow Advisor", layout="wide")
    st.title("FundFlow Advisor")
    st.markdown(
        "PDF ã¾ãŸã¯ Excel ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã€æ—¥è¨ˆã®çªåˆãŠã‚ˆã³ "
        "Gemini 2.5 ã§ã®åŸå› ç¤ºå”†ã‚’è¡Œã„ã¾ã™ã€‚"
    )

    uploaded = st.file_uploader(
        "ğŸ“ ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ï¼ˆPDF / XLS / XLSXï¼‰",
        type=None,
        accept_multiple_files=True
    )
    if not uploaded:
        st.info("ã¾ãšã¯ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")
        return

    pub_df = pd.DataFrame()
    other_dfs = {}

    for f in uploaded:
        name, ext = f.name, os.path.splitext(f.name)[1].lower()
        buf = f.read()

        if ext == ".pdf":
            df = extract_tables_from_pdf(buf)
            if df.empty:
                st.warning(f"[PDF] {name} ã®æŠ½å‡ºã«å¤±æ•—ã€‚OCRçµæœã‚’è¡¨ç¤ºã—ã¾ã™ã€‚")
                st.text_area(f"OCRï¼ˆ{name}ï¼‰", fallback_ocr_pdf(buf), height=200)
                df = pd.DataFrame()
            df = normalize_df(df)
            if pub_df.empty:
                pub_df = df
                st.subheader("å…¬é‡‘æ—¥è¨ˆãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼")
                st.dataframe(sanitize_df_for_display(pub_df))
            else:
                other_dfs[name] = df
                with st.expander(f"ä»–æ—¥å ±ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ï¼š{name}", expanded=False):
                    st.dataframe(sanitize_df_for_display(df))

        elif ext in (".xls", ".xlsx"):
            try:
                sheets = pd.read_excel(io.BytesIO(buf), sheet_name=None,
                                       engine="xlrd" if ext == ".xls" else None)
            except Exception as e:
                st.error(f"{name} ã® Excel èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
                continue
            for sheet_name, sheet_df in sheets.items():
                key = f"{name}:{sheet_name}"
                df_clean = normalize_df(sheet_df)
                other_dfs[key] = df_clean
                with st.expander(f"ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ï¼š{key}", expanded=False):
                    st.dataframe(sanitize_df_for_display(df_clean))

        else:
            st.error(f"{name} ã¯ã‚µãƒãƒ¼ãƒˆå¤–ã®æ‹¡å¼µå­ã§ã™ã€‚")

    if pub_df.empty or not other_dfs:
        st.warning("å…¬é‡‘æ—¥è¨ˆã¨ä»–æ—¥å ±ã®ä¸¡æ–¹ãŒå¿…è¦ã§ã™ã€‚")
        return

    diffs = reconcile_reports(pub_df, other_dfs)
    if diffs:
        st.subheader("â–¶ å·®ç•°ã‚µãƒãƒª")
        st.table(sanitize_df_for_display(pd.DataFrame(diffs)))
        st.subheader("â–¶ Gemini 2.5 ã«ã‚ˆã‚‹åŸå› ç¤ºå”†")
        st.markdown(generate_ai_suggestions(diffs))
    else:
        st.success("ğŸ‰ å·®ç•°ã¯æ¤œå‡ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸã€‚")

if __name__ == "__main__":
    main()
