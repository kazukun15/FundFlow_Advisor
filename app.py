import io
import re
import streamlit as st
import pdfplumber
import pandas as pd
import pytesseract
from pdf2image import convert_from_bytes
import google.generativeai as genai

# â”€â”€â”€ Streamlit Secrets ã‹ã‚‰ google.api_key ã‚’å–å¾— â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if "google" not in st.secrets or "api_key" not in st.secrets["google"]:
    st.error('`.streamlit/secrets.toml` ã«ä»¥ä¸‹ã‚’ç™»éŒ²ã—ã¦ãã ã•ã„:\n\n'
             '[google]\n'
             'api_key = "YOUR_GOOGLE_API_KEY"')
    st.stop()
genai.configure(api_key=st.secrets["google"]["api_key"])

# â”€â”€â”€ ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£é–¢æ•° â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def make_unique(cols):
    seen = {}; out = []
    for c in cols:
        cnt = seen.get(c, 0)
        name = f"{c}.{cnt}" if cnt else c
        seen[c] = cnt + 1
        out.append(name)
    return out

def extract_tables_from_pdf(buf: bytes) -> pd.DataFrame:
    with pdfplumber.open(io.BytesIO(buf)) as pdf:
        tbls = []
        for p in pdf.pages:
            for t in p.extract_tables() or []:
                if len(t) > 1:
                    df = pd.DataFrame(t[1:], columns=t[0])
                    df.columns = make_unique([str(c).strip() for c in df.columns])
                    tbls.append(df)
    if not tbls:
        return pd.DataFrame()
    all_cols = sorted({c for df in tbls for c in df.columns})
    aligned = [df.reindex(columns=all_cols) for df in tbls]
    return pd.concat(aligned, ignore_index=True, sort=False)

def ocr_text(buf: bytes) -> str:
    imgs = convert_from_bytes(buf)
    return "\n".join(pytesseract.image_to_string(img, lang="jpn") for img in imgs)

def process_public_fund_df(raw: pd.DataFrame) -> pd.DataFrame:
    mask = raw.apply(lambda row: row.astype(str).str.contains("æœˆè¨ˆå‡¦ç†æœˆ").any(), axis=1)
    if not mask.any():
        return raw
    idx = mask.idxmax()
    headers = raw.iloc[idx].tolist()
    df = raw.iloc[idx+1:].copy()
    df.columns = [str(h).strip() for h in headers]
    footer_pat = re.compile(r"ä»¤å’Œ|å°è¨ˆ|ãƒšãƒ¼ã‚¸")
    df = df[~df.iloc[:,0].astype(str).str.contains(footer_pat)]
    return df.reset_index(drop=True)

def normalize_df(df: pd.DataFrame) -> pd.DataFrame:
    df = df.copy()
    df = process_public_fund_df(df)
    df.columns = [re.sub(r"\s+", "", str(c)) for c in df.columns]
    for c in df.columns:
        cleaned = (
            df[c].astype(str)
                 .map(lambda x: re.sub(r"[^\d\.\-]", "", x))
                 .replace({"": pd.NA})
        )
        df[c] = pd.to_numeric(cleaned, errors="ignore")
    df.dropna(axis=0, how="all", inplace=True)
    df.dropna(axis=1, how="all", inplace=True)
    return df.reset_index(drop=True)

def reconcile(pub: pd.DataFrame, others: dict) -> pd.DataFrame:
    base = pub.select_dtypes("number").sum().sum()
    rows = []
    for name, df in others.items():
        tot = df.select_dtypes("number").sum().sum()
        rows.append({"ãƒ¬ãƒãƒ¼ãƒˆ": name, "å…¬é‡‘æ—¥è¨ˆåˆè¨ˆ": base, "ä»–æ—¥å ±åˆè¨ˆ": tot, "å·®ç•°": tot - base})
    return pd.DataFrame(rows)

def analyze_cf(pub: pd.DataFrame):
    ob = pub.get("ä¼šè¨ˆå‰æ—¥æ®‹é«˜", pd.Series(dtype=float)).dropna()
    ob = ob.iloc[0] if not ob.empty else None
    nums = pub.select_dtypes("number")
    sums = nums.sum().rename("åˆè¨ˆ").to_frame()
    if {"å…¥é‡‘","å‡ºé‡‘"}.issubset(nums.columns):
        infl, outf = nums["å…¥é‡‘"].sum(), nums["å‡ºé‡‘"].sum()
    elif {"åå…¥","æ”¯å‡º"}.issubset(nums.columns):
        infl, outf = nums["åå…¥"].sum(), nums["æ”¯å‡º"].sum()
    else:
        infl = nums[nums>0].sum().sum(); outf = -nums[nums<0].sum().sum()
    net = infl - outf
    return {"å‰æ—¥æ®‹é«˜": ob, "ç·æµå…¥": infl, "ç·æµå‡º": outf, "ç´”å¢—æ¸›": net}, sums

def ai_suggest(df_diff: pd.DataFrame) -> str:
    diff = df_diff[df_diff["å·®ç•°"] != 0]
    txt = diff.to_string(index=False) if not diff.empty else "ï¼ˆå·®ç•°ãªã—ï¼‰"
    prompt = f"ä»¥ä¸‹ã®å·®ç•°ã«ã¤ã„ã¦ã€åŸå› ã‚’ç®‡æ¡æ›¸ãã§ç¤ºã—ã¦ãã ã•ã„ã€‚\n\n{txt}"
    try:
        model = genai.GenerativeModel("gemini-2.5-flash-preview-04-17")
        resp = model.generate_content(prompt)
        if hasattr(resp, "text") and resp.text:
            return resp.text.strip()
        if hasattr(resp, "parts"):
            return "".join(p.text for p in resp.parts).strip()
        st.warning("AIã®å¿œç­”å½¢å¼ãŒäºˆæœŸã›ã¬ã‚‚ã®ã§ã—ãŸã€‚")
        return "AIã‹ã‚‰æœ‰åŠ¹ãªææ¡ˆã‚’å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚"
    except Exception as e:
        st.error(f"AIææ¡ˆç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
        return "AIææ¡ˆã®ç”Ÿæˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚"

def fund_advice(pub: pd.DataFrame) -> (dict, str):
    fund_cols = [c for c in pub.columns if "åŸºé‡‘" in c]
    if not fund_cols:
        return {}, "åŸºé‡‘ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚"
    sums = {c: pub[c].sum() for c in fund_cols if pd.api.types.is_numeric_dtype(pub[c])}
    table = "\n".join(f"{c}: {v:,}" for c,v in sums.items())
    prompt = (
        "ä»¥ä¸‹ã¯åŸºé‡‘ã®æ®‹é«˜æƒ…å ±ã§ã™ã€‚\n"
        f"{table}\n"
        "ä¸€èˆ¬ä¼šè¨ˆã«ç¹°ã‚Šå…¥ã‚Œï¼å„Ÿé‚„ã™ã‚‹éš›ã®æ³¨æ„ç‚¹ã¨ãŠã™ã™ã‚æ–¹æ³•ã‚’ç®‡æ¡æ›¸ãã§ç¤ºã—ã¦ãã ã•ã„ã€‚"
    )
    try:
        model = genai.GenerativeModel("gemini-2.5-flash-preview-04-17")
        resp = model.generate_content(prompt)
        txt = resp.text if hasattr(resp, "text") else "".join(p.text for p in resp.parts)
        return sums, txt.strip()
    except Exception as e:
        st.error(f"åŸºé‡‘ã‚¢ãƒ‰ãƒã‚¤ã‚¹ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
        return sums, "åŸºé‡‘ã‚¢ãƒ‰ãƒã‚¤ã‚¹ã®ç”Ÿæˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚"

# â”€â”€â”€ Streamlit UI â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def main():
    st.set_page_config(page_title="FundFlow Advisor AI", layout="wide")
    st.title("FundFlow Advisor AI")
    st.markdown("PDFã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å¾Œã€**åˆ†æé–‹å§‹**ãƒœã‚¿ãƒ³ã§å‡¦ç†ã‚’å®Ÿè¡Œã—ã¾ã™ã€‚")

    files = st.sidebar.file_uploader(
        "ğŸ“ å…¬é‡‘æ—¥è¨ˆPDF ã¨ ä»–æ—¥å ±PDFï¼ˆè¤‡æ•°å¯ï¼‰",
        type=None, accept_multiple_files=True
    )
    if not files:
        st.sidebar.info("ã“ã“ã«PDFã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")
        return

    if not st.sidebar.button("åˆ†æé–‹å§‹"):
        st.sidebar.info("æº–å‚™å®Œäº†ã€‚åˆ†æé–‹å§‹ãƒœã‚¿ãƒ³ã‚’æŠ¼ã—ã¦ãã ã•ã„ã€‚")
        return

    pub_df = pd.DataFrame(); others = {}
    for f in files:
        if not f.name.lower().endswith(".pdf"):
            st.sidebar.error(f"{f.name} ã¯PDFã§ã¯ã‚ã‚Šã¾ã›ã‚“")
            continue
        raw = extract_tables_from_pdf(f.read())
        if raw.empty:
            st.sidebar.warning(f"{f.name} è¡¨æŠ½å‡ºå¤±æ•—â†’OCRè¡¨ç¤º")
            st.sidebar.text_area(f"OCR({f.name})", ocr_text(f.read()), height=150)
            continue
        df = normalize_df(raw)
        if pub_df.empty:
            pub_df = df
            st.sidebar.success(f"{f.name} ã‚’å…¬é‡‘æ—¥è¨ˆã¨ã—ã¦è¨­å®š")
        else:
            others[f.name] = df
            st.sidebar.success(f"{f.name} ã‚’ä»–æ—¥å ±ã«è¿½åŠ ")

    # åŸºæœ¬è§£æ
    df_diff, diff_ai = pd.DataFrame(), "ä»–æ—¥å ±ãŒãªã„ãŸã‚çªåˆAIã¯ã‚ã‚Šã¾ã›ã‚“"
    if others:
        df_diff = reconcile(pub_df, others)
        diff_ai = ai_suggest(df_diff)

    cf_metrics, cf_sums = analyze_cf(pub_df)
    fund_sums, fund_ai = fund_advice(pub_df)

    tab1,tab2,tab3,tab4,tab5 = st.tabs([
        "ğŸ” ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼","ğŸ“Š å·®ç•°","ğŸ’¡ ã‚­ãƒ£ãƒƒã‚·ãƒ¥åˆ†æ","ğŸ¤– çªåˆAIææ¡ˆ","ğŸ¦ åŸºé‡‘ã‚¢ãƒ‰ãƒã‚¤ã‚¹"
    ])

    with tab1:
        st.subheader("å…¬é‡‘æ—¥è¨ˆãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼")
        st.dataframe(pub_df, use_container_width=True)
        if others:
            st.subheader("ä»–æ—¥å ±ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼")
            for name,df in others.items():
                st.markdown(f"**{name}**")
                st.dataframe(df, use_container_width=True)

    with tab2:
        st.subheader("å·®ç•°ã‚µãƒãƒªãƒ¼")
        if df_diff.empty:
            st.info("ä»–æ—¥å ±ãŒãªã„ãŸã‚å·®ç•°ã‚µãƒãƒªãƒ¼ãªã—")
        else:
            st.dataframe(df_diff, use_container_width=True)

    with tab3:
        st.subheader("ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ•ãƒ­ãƒ¼åˆ†æ")
        if cf_metrics["å‰æ—¥æ®‹é«˜"] is not None:
            st.metric("å‰æ—¥æ®‹é«˜", f"{int(cf_metrics['å‰æ—¥æ®‹é«˜']):,}")
        c1,c2,c3 = st.columns(3)
        c1.metric("ç·æµå…¥", f"{int(cf_metrics['ç·æµå…¥']):,}")
        c2.metric("ç·æµå‡º", f"{int(cf_metrics['ç·æµå‡º']):,}")
        c3.metric("ç´”å¢—æ¸›", f"{int(cf_metrics['ç´”å¢—æ¸›']):,}")
        st.subheader("åˆ—åˆè¨ˆãƒ‡ãƒãƒƒã‚°")
        st.dataframe(cf_sums, use_container_width=True)
        # ã‚°ãƒ©ãƒ•è¡¨ç¤º
        st.subheader("â–¶ å„é …ç›®åˆè¨ˆã‚°ãƒ©ãƒ•")
        st.bar_chart(cf_sums["åˆè¨ˆ"])

    with tab4:
        st.subheader("AIã«ã‚ˆã‚‹çªåˆåŸå› ææ¡ˆ")
        st.markdown(diff_ai)

    with tab5:
        st.subheader("åŸºé‡‘ã‚¢ãƒ‰ãƒã‚¤ã‚¹")
        if fund_sums:
            df_fs = pd.DataFrame.from_dict(fund_sums, orient="index", columns=["æ®‹é«˜"])
            st.table(df_fs.assign(æ®‹é«˜=lambda d: d["æ®‹é«˜"].map("{:,}".format)))
            st.subheader("â–¶ åŸºé‡‘æ®‹é«˜ã‚°ãƒ©ãƒ•")
            st.bar_chart(df_fs["æ®‹é«˜"])
        else:
            st.info("åŸºé‡‘ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
        st.markdown(fund_ai)

if __name__ == "__main__":
    main()
