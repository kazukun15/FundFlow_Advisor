import io
import re
import streamlit as st
import pdfplumber
import pandas as pd
import pytesseract
from pdf2image import convert_from_bytes
import google.generativeai as genai

# â”€â”€â”€ Streamlit Secrets ã‹ã‚‰ã®ã¿å–å¾— â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
API_SECRET_KEY = "GOOGLE_API_KEY"
if API_SECRET_KEY not in st.secrets:
    st.error(f"âŒ Streamlit Secrets ã« `{API_SECRET_KEY}` ã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚")
    st.stop()
genai.configure(api_key=st.secrets[API_SECRET_KEY])

# â”€â”€â”€ ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£é–¢æ•° â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def make_unique(cols):
    seen = {}
    out = []
    for c in cols:
        cnt = seen.get(c, 0)
        name = f"{c}.{cnt}" if cnt else c
        seen[c] = cnt + 1
        out.append(name)
    return out

def extract_tables_from_pdf(buf: bytes) -> pd.DataFrame:
    with pdfplumber.open(io.BytesIO(buf)) as pdf:
        tables = []
        for page in pdf.pages:
            for tbl in page.extract_tables() or []:
                if len(tbl) > 1:
                    df = pd.DataFrame(tbl[1:], columns=tbl[0])
                    df.columns = make_unique([str(c).strip() for c in df.columns])
                    tables.append(df)
    if not tables:
        return pd.DataFrame()
    all_cols = sorted({c for df in tables for c in df.columns})
    aligned = [df.reindex(columns=all_cols) for df in tables]
    return pd.concat(aligned, ignore_index=True, sort=False)

def ocr_text(buf: bytes) -> str:
    imgs = convert_from_bytes(buf)
    return "\n".join(pytesseract.image_to_string(img, lang="jpn") for img in imgs)

def normalize_df(df: pd.DataFrame) -> pd.DataFrame:
    df = df.copy()
    df.columns = [re.sub(r"\s+", "", str(c)) for c in df.columns]
    for c in df.columns:
        s = (
            df[c]
            .astype(str)
            .map(lambda x: re.sub(r"[^\d\.\-]", "", x))
            .replace({"": pd.NA})
        )
        df[c] = pd.to_numeric(s, errors="ignore")
    df.dropna(axis=0, how="all", inplace=True)
    df.dropna(axis=1, how="all", inplace=True)
    return df

def reconcile(pub: pd.DataFrame, others: dict) -> pd.DataFrame:
    base = pub.select_dtypes("number").sum().sum()
    rows = []
    for name, df in others.items():
        tot = df.select_dtypes("number").sum().sum()
        rows.append({
            "ãƒ¬ãƒãƒ¼ãƒˆ": name,
            "å…¬é‡‘æ—¥è¨ˆåˆè¨ˆ": base,
            "ä»–æ—¥å ±åˆè¨ˆ": tot,
            "å·®ç•°": tot - base
        })
    return pd.DataFrame(rows)

def analyze_cf(pub: pd.DataFrame):
    ob_series = pub.get("ä¼šè¨ˆå‰æ—¥æ®‹é«˜", pd.Series(dtype=float)).dropna()
    ob = ob_series.iloc[0] if not ob_series.empty else None
    nums = pub.select_dtypes("number")
    sums = nums.sum().rename("åˆè¨ˆ").to_frame()
    if {"å…¥é‡‘", "å‡ºé‡‘"}.issubset(nums.columns):
        infl, outf = nums["å…¥é‡‘"].sum(), nums["å‡ºé‡‘"].sum()
    elif {"åå…¥", "æ”¯å‡º"}.issubset(nums.columns):
        infl, outf = nums["åå…¥"].sum(), nums["æ”¯å‡º"].sum()
    else:
        infl = nums[nums > 0].sum().sum()
        outf = -nums[nums < 0].sum().sum()
    net = infl - outf
    return {"å‰æ—¥æ®‹é«˜": ob, "ç·æµå…¥": infl, "ç·æµå‡º": outf, "ç´”å¢—æ¸›": net}, sums

def ai_suggest(df_diff: pd.DataFrame) -> str:
    diff = df_diff[df_diff["å·®ç•°"] != 0]
    txt = diff.to_string(index=False) if not diff.empty else "ï¼ˆå·®ç•°ãªã—ï¼‰"
    prompt = f"ä»¥ä¸‹ã®å·®ç•°ã«ã¤ã„ã¦ã€åŸå› ã‚’ç®‡æ¡æ›¸ãã§ç¤ºã—ã¦ãã ã•ã„ã€‚\n\n{txt}"

    try:
        # æŒ‡å®šã•ã‚ŒãŸGeminiãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨
        model = genai.GenerativeModel("gemini-2.5-flash-preview-04-17")
        response = model.generate_content(prompt)
        # ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆã‚’å–ã‚Šå‡ºã—
        if hasattr(response, "text") and response.text:
            return response.text.strip()
        if hasattr(response, "parts") and response.parts:
            return "".join(p.text for p in response.parts).strip()
        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
        st.warning("AIã®å¿œç­”å½¢å¼ãŒäºˆæœŸã›ã¬ã‚‚ã®ã§ã—ãŸã€‚")
        return "AIã‹ã‚‰æœ‰åŠ¹ãªææ¡ˆã‚’å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚"
    except Exception as e:
        st.error(f"AIææ¡ˆç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
        return "AIææ¡ˆã®ç”Ÿæˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚"

# â”€â”€â”€ Streamlit UI â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def main():
    st.set_page_config(page_title="FundFlow Advisor AI", layout="wide")
    st.title("FundFlow Advisor AI")
    st.markdown("PDFã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦çªåˆãƒ»åˆ†æãƒ»AIææ¡ˆã¾ã§ä¸€æ°—é€šè²«ã€‚")

    files = st.sidebar.file_uploader(
        "ğŸ“ å…¬é‡‘æ—¥è¨ˆPDF ã¨ ä»–æ—¥å ±PDF", type=None, accept_multiple_files=True
    )
    if not files:
        st.sidebar.info("ã“ã“ã«PDFã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")
        return

    pub_df = pd.DataFrame()
    others = {}
    for f in files:
        if not f.name.lower().endswith(".pdf"):
            st.sidebar.error(f"{f.name} ã¯PDFã§ã¯ã‚ã‚Šã¾ã›ã‚“")
            continue
        buf = f.read()
        df = extract_tables_from_pdf(buf)
        if df.empty:
            st.sidebar.warning(f"{f.name} è¡¨æŠ½å‡ºå¤±æ•—â†’OCRè¡¨ç¤º")
            st.sidebar.text_area(f"OCR({f.name})", ocr_text(buf), height=150)
            continue
        df = normalize_df(df)
        if pub_df.empty:
            pub_df = df
            st.sidebar.success(f"{f.name} ã‚’åŸºæº–ã«è¨­å®š")
        else:
            others[f.name] = df
            st.sidebar.success(f"{f.name} ã‚’ä»–æ—¥å ±ã«è¿½åŠ ")

    if pub_df.empty or not others:
        st.warning("åŸºæº–PDFã¨ä»–æ—¥å ±PDFã‚’ãã‚Œãã‚Œã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")
        return

    df_diff = reconcile(pub_df, others)
    cf_metrics, cf_sums = analyze_cf(pub_df)
    ai_text = ai_suggest(df_diff)

    tab1, tab2, tab3, tab4 = st.tabs(
        ["ğŸ” ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼", "ğŸ“Š å·®ç•°ã‚µãƒãƒªãƒ¼", "ğŸ’¡ åˆ†æ", "ğŸ¤– AIææ¡ˆ"]
    )
    with tab1:
        st.subheader("â–  å…¬é‡‘æ—¥è¨ˆãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼")
        st.dataframe(pub_df, use_container_width=True)
        for name, df in others.items():
            st.subheader(f"â–  ä»–æ—¥å ±ï¼š{name}")
            st.dataframe(df, use_container_width=True)
    with tab2:
        st.subheader("â–  å·®ç•°ã‚µãƒãƒªãƒ¼")
        st.dataframe(df_diff, use_container_width=True)
    with tab3:
        st.subheader("â–  ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ•ãƒ­ãƒ¼åˆ†æ")
        if cf_metrics["å‰æ—¥æ®‹é«˜"] is not None:
            st.metric("å‰æ—¥æ®‹é«˜", f"{int(cf_metrics['å‰æ—¥æ®‹é«˜']):,}")
        c1, c2, c3 = st.columns(3)
        c1.metric("ç·æµå…¥", f"{int(cf_metrics['ç·æµå…¥']):,}")
        c2.metric("ç·æµå‡º", f"{int(cf_metrics['ç·æµå‡º']):,}")
        c3.metric("ç´”å¢—æ¸›", f"{int(cf_metrics['ç´”å¢—æ¸›']):,}")
        st.subheader("â–ª åˆ—åˆè¨ˆãƒ‡ãƒãƒƒã‚°")
        st.dataframe(cf_sums, use_container_width=True)
        if cf_metrics["ç´”å¢—æ¸›"] < 0:
            st.error("âš ï¸ è³‡é‡‘ã‚·ãƒ§ãƒ¼ãƒˆãƒªã‚¹ã‚¯")
        elif cf_metrics["ç´”å¢—æ¸›"] < cf_metrics["ç·æµå‡º"] * 0.1:
            st.warning("âš ï¸ è³‡é‡‘ä½™è£•ãŒä¹ã—ã„å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™")
        else:
            st.success("âœ… ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒã‚¸ã‚·ãƒ§ãƒ³ã¯å¥å…¨ã§ã™")
    with tab4:
        st.subheader("â–  AIã«ã‚ˆã‚‹åŸå› ææ¡ˆ")
        st.markdown(ai_text)

if __name__ == "__main__":
    main()
