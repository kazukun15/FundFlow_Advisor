import io
import os
import streamlit as st
import pdfplumber
import pandas as pd
import pytesseract
from pdf2image import convert_from_bytes
import google.generativeai as genai

# â”€â”€â”€ è¨­å®š â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.set_page_config(page_title="FundFlow Advisor", layout="wide")
api_key = st.secrets.get("google", {}).get("api_key")
if not api_key:
    st.error("âŒ Secrets ã« google.api_key ã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚")
    st.stop()
genai.configure(api_key=api_key)

# â”€â”€â”€ PDFãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def make_unique(cols):
    seen = {}
    result = []
    for col in cols:
        count = seen.get(col, 0)
        if count:
            new = f"{col}.{count}"
        else:
            new = col
        seen[col] = count + 1
        result.append(new)
    return result

def extract_tables_from_pdf(buf: bytes) -> pd.DataFrame:
    with pdfplumber.open(io.BytesIO(buf)) as pdf:
        raw_tables = []
        for page in pdf.pages:
            for table in page.extract_tables() or []:
                if len(table) > 1:
                    df = pd.DataFrame(table[1:], columns=table[0])
                    # åˆ—åã‚’æ–‡å­—åˆ—åŒ–ï¼†ãƒ¦ãƒ‹ãƒ¼ã‚¯åŒ–
                    cols = [str(c).strip() for c in df.columns]
                    df.columns = make_unique(cols)
                    raw_tables.append(df)
    if not raw_tables:
        return pd.DataFrame()
    # å…¨ãƒ†ãƒ¼ãƒ–ãƒ«ã®åˆ—ã‚’çµ±ä¸€ã—ã¦ concat
    all_cols = sorted({c for df in raw_tables for c in df.columns})
    aligned = [df.reindex(columns=all_cols) for df in raw_tables]
    return pd.concat(aligned, ignore_index=True, sort=False)

def fallback_ocr_pdf(buf: bytes) -> str:
    imgs = convert_from_bytes(buf)
    return "\n".join(pytesseract.image_to_string(img, lang="jpn") for img in imgs)

def normalize_df(df: pd.DataFrame) -> pd.DataFrame:
    df = df.copy()
    df.columns = [str(c).strip() for c in df.columns]
    for c in df.columns:
        try:
            df[c] = (
                df[c]
                .astype(str)
                .map(lambda x: x.replace(",", "").strip())
                .replace({"": pd.NA})
            )
            df[c] = pd.to_numeric(df[c], errors="ignore")
        except Exception:
            st.warning(f"âš ï¸ åˆ— '{c}' ã®æ­£è¦åŒ–ã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
    df.dropna(axis=0, how="all", inplace=True)
    df.dropna(axis=1, how="all", inplace=True)
    return df

def reconcile_reports(pub: pd.DataFrame, others: dict) -> pd.DataFrame:
    base = pub.select_dtypes(include="number").sum().sum()
    rows = []
    for name, df in others.items():
        total = df.select_dtypes(include="number").sum().sum()
        if base != total:
            rows.append({
                "ãƒ¬ãƒãƒ¼ãƒˆ": name,
                "å…¬é‡‘æ—¥è¨ˆåˆè¨ˆ": base,
                "ä»–æ—¥å ±åˆè¨ˆ": total,
                "å·®ç•°": total - base
            })
    return pd.DataFrame(rows)

def generate_ai_suggestions(df_diff: pd.DataFrame) -> str:
    prompt = (
        "ä»¥ä¸‹ã®æ—¥å ±çªåˆçµæœã«ã¤ã„ã¦ã€å·®ç•°ã®åŸå› ã‚’ç®‡æ¡æ›¸ãã§ç¤ºã—ã¦ãã ã•ã„ã€‚\n\n"
        + df_diff.to_string(index=False)
    )
    resp = genai.chat.completions.create(
        model="gemini-2.5",
        prompt=[{"author":"user","content":prompt}],
        temperature=0.7
    )
    return resp.candidates[0].message.content

# â”€â”€â”€ ãƒ¡ã‚¤ãƒ³ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def main():
    st.title("FundFlow Advisor ğŸ¦")
    st.markdown(
        "- ã‚µã‚¤ãƒ‰ãƒãƒ¼ã§PDFã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰\n"
        "- ä¸Šéƒ¨ã‚¿ãƒ–ã§ã€Œãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ã€ã€Œå·®ç•°ã‚µãƒãƒªãƒ¼ã€ã€ŒAIç¤ºå”†ã€ã‚’ç¢ºèª"
    )

    uploaded = st.sidebar.file_uploader(
        "ğŸ“ å…¬é‡‘æ—¥è¨ˆPDFã¨ä»–æ—¥å ±PDF(è¤‡æ•°å¯)", type=None, accept_multiple_files=True
    )
    if not uploaded:
        st.sidebar.info("ã“ã“ã§PDFã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")
        return

    pub_df = pd.DataFrame()
    others = {}
    for f in uploaded:
        name = f.name
        ext = os.path.splitext(name)[1].lower()
        buf = f.read()
        if ext != ".pdf":
            st.sidebar.error(f"{name} ã¯PDFã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚")
            continue
        df = extract_tables_from_pdf(buf)
        if df.empty:
            st.sidebar.warning(f"{name} æŠ½å‡ºå¤±æ•—ã€‚OCRçµæœã‚’è¡¨ç¤ºã€‚")
            st.sidebar.text_area(f"OCR({name})", fallback_ocr_pdf(buf), height=150)
            continue
        df = normalize_df(df)
        if pub_df.empty:
            pub_df = df
        else:
            others[name] = df

    if pub_df.empty or not others:
        st.warning("å…¬é‡‘æ—¥è¨ˆPDFã¨ä»–æ—¥å ±PDFã‚’ãã‚Œãã‚Œ1ä»¶ä»¥ä¸Šã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")
        return

    df_diff = reconcile_reports(pub_df, others)
    ai_text = generate_ai_suggestions(df_diff) if not df_diff.empty else ""

    tab1, tab2, tab3 = st.tabs(["ğŸ” ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼", "ğŸ“Š å·®ç•°ã‚µãƒãƒªãƒ¼", "ğŸ¤– AIç¤ºå”†"])
    with tab1:
        st.subheader("â–  å…¬é‡‘æ—¥è¨ˆãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼")
        st.code(pub_df.to_string(index=False), language="")
        for name, df in others.items():
            st.subheader(f"â–  ä»–æ—¥å ±ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼: {name}")
            st.code(df.to_string(index=False), language="")
    with tab2:
        if df_diff.empty:
            st.success("å·®ç•°ã¯æ¤œå‡ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸã€‚")
        else:
            st.subheader("â–  å·®ç•°ã‚µãƒãƒªãƒ¼")
            st.code(df_diff.to_string(index=False), language="")
    with tab3:
        if df_diff.empty:
            st.info("å·®ç•°ãŒãªã„ãŸã‚AIç¤ºå”†ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚")
        else:
            st.subheader("â–  å·®ç•°åŸå› ç¤ºå”† (Gemini 2.5)")
            st.markdown(ai_text)

if __name__ == "__main__":
    main()
