import io, re
import streamlit as st
import pdfplumber
import pandas as pd
import pytesseract
from pdf2image import convert_from_bytes
import google.generativeai as genai

# â”€â”€â”€ Secrets ã‹ã‚‰ APIã‚­ãƒ¼å–å¾— â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if "google" not in st.secrets or "api_key" not in st.secrets["google"]:
    st.error('`.streamlit/secrets.toml` ã«ä»¥ä¸‹ã‚’ç™»éŒ²ã—ã¦ãã ã•ã„:\n\n'
             '[google]\n'
             'api_key = "YOUR_GOOGLE_API_KEY"')
    st.stop()
genai.configure(api_key=st.secrets["google"]["api_key"])

# â”€â”€â”€ ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£é–¢æ•° â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def make_unique(cols):
    seen = {}
    out = []
    for c in cols:
        cnt = seen.get(c, 0)
        name = f"{c}.{cnt}" if cnt else c
        seen[c] = cnt + 1
        out.append(name)
    return out

def extract_tables_from_pdf(buf: bytes) -> pd.DataFrame:
    with pdfplumber.open(io.BytesIO(buf)) as pdf:
        tbls = []
        for p in pdf.pages:
            for t in p.extract_tables() or []:
                if len(t) > 1:
                    df = pd.DataFrame(t[1:], columns=t[0])
                    df.columns = make_unique([str(c).strip() for c in df.columns])
                    tbls.append(df)
    if not tbls:
        return pd.DataFrame()
    all_cols = sorted({c for df in tbls for c in df.columns})
    aligned = [df.reindex(columns=all_cols) for df in tbls]
    return pd.concat(aligned, ignore_index=True, sort=False)

def ocr_text(buf: bytes) -> str:
    imgs = convert_from_bytes(buf)
    return "\n".join(pytesseract.image_to_string(img, lang="jpn") for img in imgs)

def process_public_fund_df(raw: pd.DataFrame) -> pd.DataFrame:
    """
    å…¬é‡‘æ—¥è¨ˆç‰¹æœ‰ã®ãƒ˜ãƒƒãƒ€ãƒ¼ ('æœˆè¨ˆå‡¦ç†æœˆ' ã‚’å«ã‚€è¡Œ) ã‚’æ¤œå‡ºã—ã€
    ä»¥é™ã‚’ãƒ‡ãƒ¼ã‚¿ã¨ã—ã¦åˆ‡ã‚Šå‡ºã™ã€‚ä¸è¦ãªãƒ•ãƒƒã‚¿ãƒ¼è¡Œã‚’å‰Šé™¤ã€‚
    """
    # 1) ãƒ˜ãƒƒãƒ€ãƒ¼è¡Œã‚’æ¤œå‡º
    mask = raw.apply(lambda row: row.astype(str).str.contains("æœˆè¨ˆå‡¦ç†æœˆ").any(), axis=1)
    if not mask.any():
        return raw  # è¦‹ã¤ã‹ã‚‰ãªã‘ã‚Œã°ãã®ã¾ã¾è¿”ã™
    header_idx = mask.idxmax()
    headers = raw.iloc[header_idx].tolist()
    df = raw.iloc[header_idx+1:].copy()
    df.columns = [str(h).strip() for h in headers]

    # 2) ãƒ•ãƒƒã‚¿ãƒ¼ï¼ˆ"ä»¤å’Œ"ã€"å°è¨ˆ"ã€"ãƒšãƒ¼ã‚¸"ï¼‰ã‚’å«ã‚€è¡Œã‚’å‰Šé™¤
    footer_pattern = re.compile(r"ä»¤å’Œ|å°è¨ˆ|ãƒšãƒ¼ã‚¸")
    df = df[~df.iloc[:, 0].astype(str).str.contains(footer_pattern)]

    return df.reset_index(drop=True)

def normalize_df(df: pd.DataFrame) -> pd.DataFrame:
    df = df.copy()
    df = process_public_fund_df(df)   # å…¬é‡‘æ—¥è¨ˆå‘ã‘å‰å‡¦ç†ã‚’æŒŸã‚€
    # åˆ—åå…¨è§’ãƒ»åŠè§’ã‚¹ãƒšãƒ¼ã‚¹é™¤å»
    df.columns = [re.sub(r"\s+", "", str(c)) for c in df.columns]
    # å„ã‚»ãƒ«ã‹ã‚‰æ•°å­—ã®ã¿æŠ½å‡ºã—æ•°å€¤åŒ–
    for c in df.columns:
        cleaned = (
            df[c].astype(str)
                 .map(lambda x: re.sub(r"[^\d\-]", "", x))
                 .replace({"": pd.NA})
        )
        df[c] = pd.to_numeric(cleaned, errors="ignore")
    # å®Œå…¨ã«ç©ºã®è¡Œãƒ»åˆ—ã‚’å‰Šé™¤
    df.dropna(axis=0, how="all", inplace=True)
    df.dropna(axis=1, how="all", inplace=True)
    return df.reset_index(drop=True)

# ï¼ˆä»¥ä¸‹ã€ reconcileãƒ»analyze_cfãƒ»ai_suggestãƒ»fund_advice ãªã©ã¯å¤‰æ›´ãªã—ï¼‰
# â”€â”€â”€ Streamlit UI â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def main():
    st.set_page_config(page_title="FundFlow Advisor AI", layout="wide")
    st.title("FundFlow Advisor AI")
    st.markdown("å…¬é‡‘æ—¥è¨ˆPDFã¨ãã®ä»–æ—¥å ±ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã€åˆ†æãƒ»AIææ¡ˆã‚’è¡Œã„ã¾ã™ã€‚")

    files = st.sidebar.file_uploader(
        "ğŸ“ PDFã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ï¼ˆå…¬é‡‘æ—¥è¨ˆã¯å¿…é ˆã€ãã®ä»–ã¯ä»»æ„ï¼‰",
        type=None, accept_multiple_files=True
    )
    if not files:
        st.sidebar.info("ã“ã“ã«PDFã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")
        return

    pub_df = pd.DataFrame()
    others = {}
    for f in files:
        if not f.name.lower().endswith(".pdf"):
            st.sidebar.error(f"{f.name} ã¯PDFã§ã¯ã‚ã‚Šã¾ã›ã‚“"); continue
        buf = f.read()
        raw = extract_tables_from_pdf(buf)
        if raw.empty:
            st.sidebar.warning(f"{f.name} è¡¨æŠ½å‡ºå¤±æ•—â†’OCRè¡¨ç¤º")
            st.sidebar.text_area(f"OCR({f.name})", ocr_text(buf), height=150)
            continue
        df = normalize_df(raw)
        if pub_df.empty:
            pub_df = df; st.sidebar.success(f"{f.name} ã‚’å…¬é‡‘æ—¥è¨ˆã¨ã—ã¦è¨­å®š")
        else:
            others[f.name] = df; st.sidebar.success(f"{f.name} ã‚’ä»–æ—¥å ±ã«è¿½åŠ ")

    if pub_df.empty:
        st.warning("å…¬é‡‘æ—¥è¨ˆPDFãŒå¿…è¦ã§ã™ã€‚")
        return

    # ä»¥é™ã¯ã“ã‚Œã¾ã§ã¨åŒæ§˜ã« tabè¡¨ç¤ºã§çªåˆãƒ»åˆ†æãƒ»AIææ¡ˆãªã©
    # ...

if __name__ == "__main__":
    main()
